{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StatQuest: Decision Trees\n",
    "\n",
    "[Link](https://www.youtube.com/watch?v=7VeUPuFGJHk)\n",
    "\n",
    "A DT asks a question and classifies based on the answer\n",
    "\n",
    "<img src = \"./data/img/diag1.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Note: A classification can be categories or numeric\n",
    "\n",
    "In the 2nd case we are using mouse wtto predict mouse size\n",
    "\n",
    "More complex DT:\n",
    "\n",
    "<img src = \"./data/img/diag2.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "It combines numeric data:\n",
    "\n",
    "<img src = \"./data/img/diag3.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "With Yes/No data:\n",
    "\n",
    "<img src = \"./data/img/diag4.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Notice that cut-off for Resting heart rate need not be same on both sides\n",
    "\n",
    "<img src = \"./data/img/diag5.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Also order of questions need not be same on both sides\n",
    "\n",
    "The final classifications may be repeated\n",
    "\n",
    "U start at top and go down till u get to a pt where u cant go further\n",
    "\n",
    "Thats how a sample is classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw table of data to DT:\n",
    "\n",
    "We want to create a tree that uses **chest pain, good blood circulation, blocked artery status** to predict\n",
    "**heart disease(y/n)**\n",
    "\n",
    "We want to decide which of **chest pain, good blood circulation, blocked artery status** should be root node\n",
    "\n",
    "<img src = \"./data/img/diag6.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "We start off by exploring how well Chest pain classifies heart disease and build a tree as shown below:\n",
    "\n",
    "<img src = \"./data/img/diag7.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "We build similar trees for Good Blood Circulation and blocked Artery\n",
    "\n",
    "<img src = \"./data/img/diag8.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "As shown above we dont kno the BA status for this patient. We skip it but there are other alternatives\n",
    "\n",
    "As there are missing values for a feature the total number of patients in each tree is diff\n",
    "\n",
    "<img src = \"./data/img/diag9.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "** because none of the leaf nodes are 100% YES Heart disease or 100% NO they all are considered as \"impure\"**\n",
    "\n",
    "To determine which separation is best we need a way to measure and compare impurity\n",
    "\n",
    "#### Gini method to measure impurity\n",
    "\n",
    "Gini impurity (GI) is calculated for each leaf node as shown below:\n",
    "\n",
    "<img src = \"./data/img/diag10.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Similarly we calculate GI for right leaf node\n",
    "\n",
    "The leaf nodes do not reppresent same number of patients\n",
    "\n",
    "Thus total GI for using Chest pain as root node is the weighted avg of GI of the 2 nodes:\n",
    "\n",
    "<img src = \"./data/img/diag11.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "Similarly we calculate GI for all 3 possible root nodes\n",
    "\n",
    "<img src = \"./data/img/diag12.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "Good blood circulation has lowest impurity and it separates the people with or without heart disease the best\n",
    "\n",
    "So first node (root) = GBC\n",
    "\n",
    "After the split we get 2 leaf nodes\n",
    "\n",
    "Left: (37 y, 127 n)\n",
    "\n",
    "Right: (100 y, 33 n)\n",
    "\n",
    "Now we need to figure out how to separate (and if we should separate further) these patients in the Left and Right\n",
    "\n",
    "**Lets start with left:**\n",
    "\n",
    "These are the patients with GBC == true\n",
    "\n",
    "Just like before we separate these patients based on CP and calculate GI as before\n",
    "\n",
    "We do same for Blocked Artery\n",
    "\n",
    "GI for BA = 2.9\n",
    "\n",
    "This is less than GI for CP and also less than GI for GBC\n",
    "\n",
    "<img src = \"./data/img/diag13.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Thus we use BA in the left part\n",
    "\n",
    "Resulting tree:\n",
    "\n",
    "<img src = \"./data/img/diag14.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Now we will use CP to try and separate the L->L node(24/25)\n",
    "\n",
    "These are the patients with GBC = true and BA = true\n",
    "\n",
    "CP does a good job in separating the patients:\n",
    "\n",
    "<img src = \"./data/img/diag15.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Now we look at node in Root->L->R (13/102)\n",
    "\n",
    "Lets try and use CP to divide these 115 patients\n",
    "\n",
    "Note : ** Vast majority (89%) of patients in this node dont have heart disease**\n",
    "\n",
    "<img src = \"./data/img/diag16.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "After separating we get a higher GI than before separating\n",
    "\n",
    "So we make this node a leaf node\n",
    "\n",
    "<img src = \"./data/img/diag17.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "We have built the entire LHS of the tree\n",
    "\n",
    "<img src = \"./data/img/diag18.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "For RHS we follow same steps:\n",
    "\n",
    "1. Calculate all GI scores\n",
    "\n",
    "2. If node otself has lowest score, then there is no point in separating and the node becomes a leaf node\n",
    "\n",
    "3. If separating the data results in an improvement, pick the separation with the lowest impurity value\n",
    "\n",
    "Complete tree:\n",
    "\n",
    "<img src = \"./data/img/diag18.1.png\" height=\"700\" width = \"700\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric data in DT:\n",
    "\n",
    "Imagine if our features were numeric not just Y/N:\n",
    "\n",
    "<img src = \"./data/img/diag19.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "1. Sort patients by wt (lowest to highest)\n",
    "\n",
    "<img src = \"./data/img/diag20.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "2. Calculate avg wts for all adjacent patients\n",
    "\n",
    "3. Calculate GI for each avg wt\n",
    "\n",
    "<img src = \"./data/img/diag21.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "In the above diag GI is calculated for wt < 167.5\n",
    "\n",
    "4. The lowest GI occurs when wt < 205 (GI=0.27)\n",
    "\n",
    "<img src = \"./data/img/diag22.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "So this is the cutoff that we will use when we compare wt to CP or BA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DT with ranked data and multiple choice data\n",
    "\n",
    "Ranked data is similar to numeric data, except that now we calculate impurity scores for **all possiblle ranks**\n",
    "\n",
    "So if rank is from 1 to 4 (4 being best), we calculate impurity scores as:\n",
    "\n",
    "- rank <= 1\n",
    "\n",
    "- rank <= 2\n",
    "\n",
    "- rank <= 3\n",
    "\n",
    "We dont need <=4 as it includes everyone\n",
    "\n",
    "When there are multiple choices like color choices - B, R or G we calculate GI for each one as well as each possible combination\n",
    "\n",
    "- B\n",
    "\n",
    "- G\n",
    "\n",
    "- R\n",
    "\n",
    "- B or G\n",
    "\n",
    "- B or R\n",
    "\n",
    "- G or R\n",
    "\n",
    "We dont need to calculate for B or R or G as it includes everyone\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StatQuest: Random Forests Part 1 - Building, Using and Evaluating\n",
    "\n",
    "[Link](https://www.youtube.com/watch?v=J4Wdy0Wc_xQ&t=143s)\n",
    "\n",
    "DTs are easy to build, use and interpret\n",
    "\n",
    "But in practice, theyare not that awesome\n",
    "\n",
    "> Trees have one aspect that prevents them from being the ideal tool for predictive learning, namely **inaccuracy**\n",
    "\n",
    "** They work great with the data used to create them but are not flexible when it comes to classifying\n",
    "new samples**\n",
    "\n",
    "RF combines simplicity of DTs with flexibility resulting in a vast improvement in accuracy\n",
    "\n",
    "\n",
    "#### Step 1 : Create a \"bootstrapped\" dataset\n",
    "\n",
    "<img src = \"./data/img/diag23.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Say these 4 samples are entire dataset\n",
    "\n",
    "To create a bootstrapped dataset that is same size as original we randomly select samples from original dataset\n",
    "\n",
    "**We are allowed to pick the same sample more than once**\n",
    "\n",
    "Say first sample in original dataset = S1\n",
    "\n",
    "We create bootstrap dataset as: **S2, S1, S4, S4**\n",
    "\n",
    "<img src = \"./data/img/diag24.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "#### Step 2: Create a DT using Bootstrapped dataset but only use a random subset of vars (columns) at each step\n",
    "\n",
    "In this example we will consider 2 vars at each step\n",
    "\n",
    "Thus instead of considering all 4 vars (CP, GBC, BA, Wt) to figure out how to split the root node we randomly select 2 : GBC, BA\n",
    "\n",
    "Say GBC did the best job at separating the samples\n",
    "\n",
    "We used GBC, we grey it out, so that we can focus on rem vars\n",
    "\n",
    "<img src = \"./data/img/diag25.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Now we have to figure out how to select vars ffor circled node:\n",
    "\n",
    "<img src = \"./data/img/diag26.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Just like for the root we randomly select 2 vars from (CP, BA, wt)\n",
    "\n",
    "We select CP and wt\n",
    "\n",
    "Thus we build the tree by: \n",
    "\n",
    "1. using the bootstrapped dataset\n",
    "\n",
    "2. considering a random subset of vars at each step\n",
    "\n",
    "This is done for a single tree\n",
    "\n",
    "Now we make a new bootstrapped dataset and build tree considering a random subset of vars at each step\n",
    "\n",
    "Ideally we do this 100s of times\n",
    "\n",
    "considering a random subset of vars at each step\n",
    "\n",
    "<img src = \"./data/img/diag27.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "Because of the randomness associated with creating the bootsrapped dataset and also due to choosing random columns for each step, RF results in a ** wide variety of DTs**\n",
    "\n",
    "This variety makes RF more effevtive that DTs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have created the RF, how do we use it?\n",
    "\n",
    "First we get data of a new patient\n",
    "\n",
    "We want to predict if Heart disease or not\n",
    "\n",
    "We take data and run down 1st tree\n",
    "\n",
    "Output: Yes\n",
    "\n",
    "We keep track of this result\n",
    "\n",
    "<img src = \"./data/img/diag28.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Similarly we run data thru 2nd... last tree\n",
    "\n",
    "We keep track of the results and see which option received most votes\n",
    "\n",
    "Here Yes: 5 No : 1\n",
    "\n",
    "So conclusion : YES\n",
    "\n",
    "**Bagging** : Bootstrapping the data plus using the aggregrate to make a decision is called Bagging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy of a RF\n",
    "\n",
    "When we created the bootstrapped dataset we allowed duplicate entries in the bootstrapped dataset\n",
    "\n",
    "<img src = \"./data/img/diag29.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "As a result above entry was not included in the bootstrapped dataset\n",
    "\n",
    "> Typically about 1/3 the original data does not end up in the bootstrapped dataset\n",
    "\n",
    "These entries are called the **Out-of-Bag Dataset**\n",
    "\n",
    "We know the results of OoB data\n",
    "\n",
    "Say there is only 1 entry in OoB data = No\n",
    "\n",
    "we use them to test\n",
    "\n",
    "We run the data through our first DT\n",
    "\n",
    "Result : No\n",
    "\n",
    "Similarly we run throuugh all trees and keep track of the results\n",
    "\n",
    "Then we chose the most common result: Here it is correct and = No\n",
    "\n",
    "<img src = \"./data/img/diag30.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "We repeat the process for all OoB samples for all trees\n",
    "\n",
    "Some may be incorrectly labeled\n",
    "\n",
    "**Accuracy**: Proportion of OoB Samples that were correctly claasified by the RF\n",
    "\n",
    "The proportion of OoB smaples that were incorrectly classified is the **OoB Error**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know how to:\n",
    "\n",
    "- Build a RF\n",
    "\n",
    "- Use a RF\n",
    "\n",
    "- Estimate accuracy of RF\n",
    "\n",
    "<img src = \"./data/img/diag31.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "We used 2 vars to make a decision at each step\n",
    "\n",
    "Now we can compare OoB Error for RF built using 2vars per step to a RF built using 3 vars per step\n",
    "\n",
    "We can test many diff settings and chose the most accurate RF\n",
    "\n",
    "Process:\n",
    "\n",
    "1. Build a RF\n",
    "\n",
    "2. Est accuracy of RF\n",
    "\n",
    "3. Change no of vars used per step\n",
    "\n",
    "4. Repeat for a number of times and chose the RF that is most accurate\n",
    "\n",
    "Typically we start by using the square of number (sq root?) and then try a few settings above and below that value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StatQuest: Random Forests Part 2: Missing data and clustering\n",
    "\n",
    "[Link](https://www.youtube.com/watch?v=nyxTdL_4Q-Q)\n",
    "\n",
    "Lets see how RF deals with missing data\n",
    "\n",
    "Missing data can be of 2 types:\n",
    "\n",
    "<img src = \"./data/img/diag32.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "- Missing data can be in original dataset\n",
    "- It may be in a new sample we want to categorize\n",
    "\n",
    "Lets start with **Missing data in the original dataset**:\n",
    "\n",
    "We want to create a RF from the data\n",
    "\n",
    "But we dont know if the 4th patient has BA or what is their wt\n",
    "\n",
    "We make an initial guess that mey be bad and gradually refine the guess until it (hopefully) gets good\n",
    "\n",
    "Initial guess for BA = most common value = No\n",
    "\n",
    "Since wt is numeric our initial guess is the median val = 180\n",
    "\n",
    "<img src = \"./data/img/diag33.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "This is the dataset with the initial guesses\n",
    "\n",
    "Now we want to refine our guesses\n",
    "\n",
    "We do this by ** detemining which samples are similar to the one with the missing data**\n",
    "\n",
    "#### Determining Similarity:\n",
    "\n",
    "1. Build a RF\n",
    "\n",
    "2. Run all of the data down all of the trees\n",
    "\n",
    "Lets start by running all of the data down the 1st tree:\n",
    "\n",
    "<img src = \"./data/img/diag34.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Say sample 3 and 4 ended up in the same leaf node\n",
    "\n",
    "That means they are **simialar (that is how similarity is defined in RF)**\n",
    "\n",
    "We keep track of similar samples using a **Proximity Matrix**\n",
    "\n",
    "The PM has a row foreach sample and a col for each sample\n",
    "\n",
    "<img src = \"./data/img/diag35.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "As samples 3 and 4 are similar we put 1 there\n",
    "\n",
    "Similarly we run all of the data down the 2nd tree\n",
    "\n",
    "<img src = \"./data/img/diag36.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Now samples 2, 3 and 4 all ended up in the same leaf nodes\n",
    "\n",
    "PM now:\n",
    "\n",
    "<img src = \"./data/img/diag37.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "We add 1 as the pairs come in smae leaf node again\n",
    "\n",
    "We run all the data down the 3rd tree\n",
    "\n",
    "Updated PM:\n",
    "\n",
    "<img src = \"./data/img/diag38.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Ultimately, we run the data down all the trees and the PM fills in\n",
    "\n",
    "<img src = \"./data/img/diag39.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Then we divide each proximity value by total number of trees (say we had 10 trees)\n",
    "\n",
    "Updated PM:\n",
    "\n",
    "<img src = \"./data/img/diag40.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Now we can use the proximity values for sample 4 to make better guesses about the missing data\n",
    "\n",
    "\n",
    "For BA we calculate the weighted freq of Y and N using prox values as wts\n",
    "\n",
    "<img src = \"./data/img/diag41.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Calculations:\n",
    "\n",
    "> Freq of Yes = 1/3\n",
    "\n",
    "> Freq of No = 2/3\n",
    "\n",
    "> The wighted freq of Yes = Freq of Yes * The weight for Yes\n",
    "\n",
    "> The weight for Yes = (Proximity of Yes)/(All proximities)\n",
    "\n",
    "<img src = \"./data/img/diag42.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "> The proximity for Yes = Proximity value for sample 2 (the only one with Yes)\n",
    "\n",
    "> We divide that by sum of proximities for sample 4\n",
    "\n",
    "<img src = \"./data/img/diag43.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "> The weight for Yes = 0.1/(0.1 + 0.1 + 0.8) = 0.1\n",
    "\n",
    "> The wighted freq of Yes = 1/3 * 0.1 = 0.03\n",
    "\n",
    "Similarly,\n",
    "\n",
    "> The wighted freq of No = Freq of No * The weight for No\n",
    "\n",
    "> The weight for No = (0.1 + 0.8)/(0.1 + 0.1 + 0.8) = 0.9\n",
    "\n",
    "> The wighted freq of No = 2/3 * 0.9 = 0.6\n",
    "\n",
    "Since No has a way higher wt freq we chose No\n",
    "\n",
    "**So our new, improved revised guess based on proximities for BA is No**\n",
    "\n",
    "** Filling in missing values for wt:**\n",
    "\n",
    "For wt we use proximities to calculate a weighted avg\n",
    "\n",
    "\n",
    "\n",
    "> Weighted avg = (wt of sample 1 * wt avg wt of sample 1) + (wt of sample 2 * wt avg wt of sample 2) + (wt of sample 3 * wt avg wt of sample 3)\n",
    "\n",
    "\n",
    "> wt avg wt of sample 1 = (proximity of sample 1) / (sum of proximities) = 0.1 / (0.1 + 0.1 + 0.8) = 0.1\n",
    "\n",
    "<img src = \"./data/img/diag44.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "Similarly we calculate wt avg wt of sample 2 and wt avg wt of sample 3\n",
    "\n",
    "> Weighted avg = (125 * 0.1) + (180 * 0.1) + (210 * 0.8) = 198.5\n",
    "\n",
    "wts used to calculate the weighted avg is based on proximities\n",
    "\n",
    "So we fill missing val as 198.5\n",
    "\n",
    "\n",
    "<img src = \"./data/img/diag45.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Now that we have revised our guesses a little bit, we do the whole thing over again..\n",
    "\n",
    "- we build a RF\n",
    "- run data thru the trees\n",
    "- recalculate proximities\n",
    "- recalculate missing vals\n",
    "- we do this 6 or 7 times until the missing values converge i.e. no longer change each time we recalculate\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Super Cool stuff with the PM:\n",
    "\n",
    "<img src = \"./data/img/diag46.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "We have already seen this PM \n",
    "\n",
    "This is the PM b4 we divided each value by 10\n",
    "\n",
    "If samples 3 and 4 ended up in the same leaf node for all 10 trees:\n",
    "\n",
    "<img src = \"./data/img/diag47.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "We divide each number by 10\n",
    "\n",
    "For Samples 3 and 4 the entry will be 1\n",
    "\n",
    "1 in PM => samples are as close as they can be\n",
    "\n",
    "Also\n",
    "\n",
    "1 - prox value = distance\n",
    "\n",
    "<img src = \"./data/img/diag48.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "Thus it is possible to derive a ** Distance Matrix ** from the PM\n",
    "\n",
    "Getting distance matrix (which is similar to corr matrix) means we can plot **Heat Maps**\n",
    "\n",
    "<img src = \"./data/img/diag49.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "We can also draw **MDS Plots**\n",
    "\n",
    "<img src = \"./data/img/diag50.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing data in new sample that we want to categorize\n",
    "\n",
    "Imagine that we have already built a RF and we wanted to classify a new patient\n",
    "\n",
    "But the patient has missing data for BA\n",
    "\n",
    "<img src = \"./data/img/diag51.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "\n",
    "We dont know if patient has BA\n",
    "\n",
    "So we need to make a guess about BA so that we can run the patient down all the trees in the forest\n",
    "\n",
    "1. Create 2 copies of the data (Yes and No for Heart Disease \n",
    "\n",
    "<img src = \"./data/img/diag52.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "2. Then we use the iterative method discussed about to make a good guess about the misssing values\n",
    "\n",
    "<img src = \"./data/img/diag53.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "3. These are the guesses that we came up with:\n",
    "\n",
    "<img src = \"./data/img/diag54.png\" height=\"700\" width = \"700\" align=\"center\">\n",
    "\n",
    "4. Then we run the 2 samples down the trees in the forest\n",
    "\n",
    "5. Then we see which of the 2 is correctly labeled by the RF most number of times\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
