{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Using Jupyter\n",
    "\n",
    "Jupyter is a front end to the [IPython](https://ipython.org) interactive shell, and offers IDE like features.  It is separated into two main types of cell: [Markdown](https://en.wikipedia.org/wiki/Markdown) cells (such as this one) which allows markdown or HTML code to be written, and code cells like the next one which can be run in real time.\n",
    "\n",
    "To execute code in a cell, press `Crtl` + `Enter`, click on the `[ > ]Run` button in the main menu, or press `Shift` + `Enter` if you wish to execute the code and then move on to a new cell (creating it if it does not already exist).\n",
    "\n",
    "## Setup\n",
    "\n",
    "MongoDB is a NoSQL database, which has a core API in JavaScript, and a series of other APIs in different languages.  The one we are going to use is the Python API, [PyMongo](https://api.mongodb.com/python/current/).  MongoDB instance on your VM is already started by default.\n",
    "\n",
    "PyMongo is a package that contains tools to work with MongoDB from Python. We have installed it in the VM provided to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imports the `MongoClient` class from the pymongo module, which we will use to deal with all our connections from.  We're connecting to our localhost, which is listening on port 27017. There are more options, the documentation for the formatting of the connection string is at https://docs.mongodb.com/manual/reference/connection-string/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading https://files.pythonhosted.org/packages/b1/45/5440555b901a8416196fbf2499c4678ef74de8080c007104107a8cfdda20/pymongo-3.7.2-cp36-cp36m-manylinux1_x86_64.whl (408kB)\n",
      "\u001b[K    100% |████████████████████████████████| 409kB 1.5MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pymongo\n",
      "Successfully installed pymongo-3.7.2\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://localhost:27017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not get any errors, you have confirmed PyMongo library has been successfully installed&configured in the VM. We will now check to see whether the connection is correct.  The following code calls a function which returns a list of all current databases.  If your Mongo instance is still empty, it should be something like `['admin', 'local']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin',\n",
       " 'client-app-1',\n",
       " 'client-app-2',\n",
       " 'conFusion',\n",
       " 'local',\n",
       " 'mongo_lab',\n",
       " 'mycustomers']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to create a database object `db`, which is a property of the `client` object.  MongoDB is schemaless, and so accessing a database like this will create the database if it does not already exist.\n",
    "\n",
    "A database can be accessed by using \"dot\" notation (i.e., `client.dbname`), or dictionary notation (i.e., `client['dbname']`).  This also applies to making collections\n",
    "\n",
    "Create a database called `test` in a variable called `db`.  Using that variable, create a collection called `test_collection` with a variable called `collection` as follows.  Run the code in the following cell (there should not be any output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database and collection objects for convenience\n",
    "db = client.mongo_lab\n",
    "collection = db.test_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MongoDB\n",
    "\n",
    "## Inserting data\n",
    "\n",
    "MongoDB data is stored as BSON (binary JSON), which is essentially JSON with some additional optimisations, so the way to insert data is as a JSON object.  For Python, you can use a `dict` or a `list` for this, and then call either `insert_one` or `insert_many` on the collection.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7f1dc882ff48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an object and insert into the `test_collection`\n",
    "single_obj = {'name': 'Amber', 'star_sign': 'Capricorn', 'favourite_song': 'The Load-Out'}\n",
    "collection.insert_one(single_obj)\n",
    "single_obj_2 = {'name': 'Huw', 'star_sign': 'Libra', 'favourite_song': 'The masses against the classes'}\n",
    "collection.insert_one(single_obj_2)\n",
    "single_obj_3 = {'name': 'Robert', 'star_sign': 'Leo', 'favourite_song': 'Bad day'}\n",
    "collection.insert_one(single_obj_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at querying data in more detail below, but for now, to see whether the object got successfully inserted into the collection, run the code below.  This will always return the first instance which matches the query.  You will notice that even though we didn't specify `_id` one got added already.  This is a unique identifier for the document in the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5c09b5f9651cff367fe07129'),\n",
       " 'favourite_song': 'The Load-Out',\n",
       " 'name': 'Amber',\n",
       " 'star_sign': 'Capricorn'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find_one() # returns a single document matching the query condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5c09b5f9651cff367fe0712b'),\n",
       " 'favourite_song': 'Bad day',\n",
       " 'name': 'Robert',\n",
       " 'star_sign': 'Leo'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find_one({'name':'Robert'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, for MongoDB, you do not have to specify a schema or create a collection, it will be created automatically.  You don't need to keep to the same layout, but can have entirely different objects.  Consider the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7f1dc9134b48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "obj1 = {'Meaning of life': 42}\n",
    "obj2 = {'ABC': 'DEF', 'time': datetime.now()}\n",
    "collection.insert_one(obj1)\n",
    "collection.insert_one(obj2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `insert_many`, which accepts a list of dicts.  In the cell below, create a list of dicts called `many_objects`, and call the `insert_many` function.  The code below that will iterate over all the documents in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5c09b5f9651cff367fe07129'),\n",
      " 'favourite_song': 'The Load-Out',\n",
      " 'name': 'Amber',\n",
      " 'star_sign': 'Capricorn'}\n",
      "{'_id': ObjectId('5c09b5f9651cff367fe0712a'),\n",
      " 'favourite_song': 'The masses against the classes',\n",
      " 'name': 'Huw',\n",
      " 'star_sign': 'Libra'}\n",
      "{'_id': ObjectId('5c09b5f9651cff367fe0712b'),\n",
      " 'favourite_song': 'Bad day',\n",
      " 'name': 'Robert',\n",
      " 'star_sign': 'Leo'}\n",
      "{'Meaning of life': 42, '_id': ObjectId('5c09b642651cff367fe0712c')}\n",
      "{'ABC': 'DEF',\n",
      " '_id': ObjectId('5c09b642651cff367fe0712d'),\n",
      " 'time': datetime.datetime(2018, 12, 6, 23, 52, 34, 776000)}\n",
      "{'_id': ObjectId('5c09b741651cff367fe0712e'),\n",
      " 'age': 23,\n",
      " 'name': 'Mini',\n",
      " 'planet': 'unknown'}\n",
      "{'_id': ObjectId('5c09b741651cff367fe0712f'), 'age': 25, 'name': 'Paddy'}\n",
      "{'_id': ObjectId('5c09b741651cff367fe07130'),\n",
      " 'name': 'Saurav',\n",
      " 'planet': 'Earth'}\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "list_of_dicts = [\n",
    "    {\n",
    "        \"name\": \"Mini\",\n",
    "        \"age\": 23,\n",
    "        \"planet\": \"unknown\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Paddy\",\n",
    "        \"age\": 25\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Saurav\",\n",
    "        \"planet\": \"Earth\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# collection.insert_many(list_of_dicts)\n",
    "\n",
    "\n",
    "#See what has been inserted into the collection\n",
    "for doc in collection.find():\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and querying data\n",
    "\n",
    "For this part of the exercise, we will use a sample dataset provided by Mongo  for a documentation tutorial.  The following cell runs the `mongoimport` command, which is a Unix command which comes with Mongo for importing data. We will need to run a bash command in the next cell first.  This uses the Jupyter \\\"magics\\\", and requires that the first line include `%%bash`. The code does the following:\n",
    "\n",
    "- Download the JSON file from the url, and save as ./primer-dataset.json\n",
    "- Import into the `test` database into the collection `restaurants` whilst dropping any collection which already exists from the file ./primer-dataset.json\n",
    "- Deletes the file.\n",
    "\n",
    " Click on the following cell, and execute it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2018-12-06 23:57:58--  https://raw.githubusercontent.com/mongodb/docs-assets/primer-dataset/primer-dataset.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.16.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.16.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11874761 (11M) [text/plain]\n",
      "Saving to: ‘primer-dataset.json’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 1.78M 6s\n",
      "    50K .......... .......... .......... .......... ..........  0% 3.40M 5s\n",
      "   100K .......... .......... .......... .......... ..........  1% 7.36M 4s\n",
      "   150K .......... .......... .......... .......... ..........  1% 2.46M 4s\n",
      "   200K .......... .......... .......... .......... ..........  2% 3.91M 4s\n",
      "   250K .......... .......... .......... .......... ..........  2% 1.87M 4s\n",
      "   300K .......... .......... .......... .......... ..........  3% 4.70M 4s\n",
      "   350K .......... .......... .......... .......... ..........  3% 5.19M 4s\n",
      "   400K .......... .......... .......... .......... ..........  3% 4.50M 3s\n",
      "   450K .......... .......... .......... .......... ..........  4% 3.57M 3s\n",
      "   500K .......... .......... .......... .......... ..........  4% 4.81M 3s\n",
      "   550K .......... .......... .......... .......... ..........  5% 3.71M 3s\n",
      "   600K .......... .......... .......... .......... ..........  5% 4.30M 3s\n",
      "   650K .......... .......... .......... .......... ..........  6% 4.70M 3s\n",
      "   700K .......... .......... .......... .......... ..........  6% 6.48M 3s\n",
      "   750K .......... .......... .......... .......... ..........  6% 4.06M 3s\n",
      "   800K .......... .......... .......... .......... ..........  7% 4.25M 3s\n",
      "   850K .......... .......... .......... .......... ..........  7% 4.71M 3s\n",
      "   900K .......... .......... .......... .......... ..........  8% 7.24M 3s\n",
      "   950K .......... .......... .......... .......... ..........  8% 3.59M 3s\n",
      "  1000K .......... .......... .......... .......... ..........  9% 3.61M 3s\n",
      "  1050K .......... .......... .......... .......... ..........  9% 4.36M 3s\n",
      "  1100K .......... .......... .......... .......... ..........  9% 6.36M 3s\n",
      "  1150K .......... .......... .......... .......... .......... 10% 2.37M 3s\n",
      "  1200K .......... .......... .......... .......... .......... 10% 1.98M 3s\n",
      "  1250K .......... .......... .......... .......... .......... 11% 3.96M 3s\n",
      "  1300K .......... .......... .......... .......... .......... 11% 50.0M 3s\n",
      "  1350K .......... .......... .......... .......... .......... 12% 3.47M 3s\n",
      "  1400K .......... .......... .......... .......... .......... 12% 4.42M 3s\n",
      "  1450K .......... .......... .......... .......... .......... 12% 3.18M 3s\n",
      "  1500K .......... .......... .......... .......... .......... 13% 5.41M 3s\n",
      "  1550K .......... .......... .......... .......... .......... 13% 3.37M 3s\n",
      "  1600K .......... .......... .......... .......... .......... 14% 2.23M 3s\n",
      "  1650K .......... .......... .......... .......... .......... 14% 4.49M 3s\n",
      "  1700K .......... .......... .......... .......... .......... 15% 5.69M 3s\n",
      "  1750K .......... .......... .......... .......... .......... 15% 5.87M 3s\n",
      "  1800K .......... .......... .......... .......... .......... 15% 5.26M 2s\n",
      "  1850K .......... .......... .......... .......... .......... 16% 4.76M 2s\n",
      "  1900K .......... .......... .......... .......... .......... 16% 3.40M 2s\n",
      "  1950K .......... .......... .......... .......... .......... 17% 8.81M 2s\n",
      "  2000K .......... .......... .......... .......... .......... 17% 1.50M 2s\n",
      "  2050K .......... .......... .......... .......... .......... 18% 6.58M 2s\n",
      "  2100K .......... .......... .......... .......... .......... 18% 2.85M 2s\n",
      "  2150K .......... .......... .......... .......... .......... 18% 1.09M 3s\n",
      "  2200K .......... .......... .......... .......... .......... 19% 3.87M 3s\n",
      "  2250K .......... .......... .......... .......... .......... 19% 2.92M 3s\n",
      "  2300K .......... .......... .......... .......... .......... 20% 8.79M 3s\n",
      "  2350K .......... .......... .......... .......... .......... 20% 2.33M 3s\n",
      "  2400K .......... .......... .......... .......... .......... 21%  366K 3s\n",
      "  2450K .......... .......... .......... .......... .......... 21% 2.98M 3s\n",
      "  2500K .......... .......... .......... .......... .......... 21% 24.5M 3s\n",
      "  2550K .......... .......... .......... .......... .......... 22% 2.14M 3s\n",
      "  2600K .......... .......... .......... .......... .......... 22% 4.90M 3s\n",
      "  2650K .......... .......... .......... .......... .......... 23% 1.82M 3s\n",
      "  2700K .......... .......... .......... .......... .......... 23% 2.35M 3s\n",
      "  2750K .......... .......... .......... .......... .......... 24% 4.53M 3s\n",
      "  2800K .......... .......... .......... .......... .......... 24% 2.91M 3s\n",
      "  2850K .......... .......... .......... .......... .......... 25% 4.00M 3s\n",
      "  2900K .......... .......... .......... .......... .......... 25% 2.28M 3s\n",
      "  2950K .......... .......... .......... .......... .......... 25% 3.43M 3s\n",
      "  3000K .......... .......... .......... .......... .......... 26% 3.74M 3s\n",
      "  3050K .......... .......... .......... .......... .......... 26% 5.64M 3s\n",
      "  3100K .......... .......... .......... .......... .......... 27% 3.55M 3s\n",
      "  3150K .......... .......... .......... .......... .......... 27% 7.44M 3s\n",
      "  3200K .......... .......... .......... .......... .......... 28% 2.59M 3s\n",
      "  3250K .......... .......... .......... .......... .......... 28% 6.60M 3s\n",
      "  3300K .......... .......... .......... .......... .......... 28% 5.00M 3s\n",
      "  3350K .......... .......... .......... .......... .......... 29% 4.16M 3s\n",
      "  3400K .......... .......... .......... .......... .......... 29% 4.49M 3s\n",
      "  3450K .......... .......... .......... .......... .......... 30% 3.69M 3s\n",
      "  3500K .......... .......... .......... .......... .......... 30% 5.86M 2s\n",
      "  3550K .......... .......... .......... .......... .......... 31% 1.17M 3s\n",
      "  3600K .......... .......... .......... .......... .......... 31% 2.53M 3s\n",
      "  3650K .......... .......... .......... .......... .......... 31% 5.55M 2s\n",
      "  3700K .......... .......... .......... .......... .......... 32% 3.94M 2s\n",
      "  3750K .......... .......... .......... .......... .......... 32% 3.56M 2s\n",
      "  3800K .......... .......... .......... .......... .......... 33% 3.50M 2s\n",
      "  3850K .......... .......... .......... .......... .......... 33% 2.57M 2s\n",
      "  3900K .......... .......... .......... .......... .......... 34% 4.15M 2s\n",
      "  3950K .......... .......... .......... .......... .......... 34% 4.37M 2s\n",
      "  4000K .......... .......... .......... .......... .......... 34% 4.44M 2s\n",
      "  4050K .......... .......... .......... .......... .......... 35% 4.42M 2s\n",
      "  4100K .......... .......... .......... .......... .......... 35% 4.13M 2s\n",
      "  4150K .......... .......... .......... .......... .......... 36% 3.11M 2s\n",
      "  4200K .......... .......... .......... .......... .......... 36% 5.06M 2s\n",
      "  4250K .......... .......... .......... .......... .......... 37% 3.00M 2s\n",
      "  4300K .......... .......... .......... .......... .......... 37% 4.12M 2s\n",
      "  4350K .......... .......... .......... .......... .......... 37% 3.79M 2s\n",
      "  4400K .......... .......... .......... .......... .......... 38% 3.09M 2s\n",
      "  4450K .......... .......... .......... .......... .......... 38% 4.04M 2s\n",
      "  4500K .......... .......... .......... .......... .......... 39% 2.21M 2s\n",
      "  4550K .......... .......... .......... .......... .......... 39% 8.63M 2s\n",
      "  4600K .......... .......... .......... .......... .......... 40% 2.17M 2s\n",
      "  4650K .......... .......... .......... .......... .......... 40% 1.73M 2s\n",
      "  4700K .......... .......... .......... .......... .......... 40% 2.06M 2s\n",
      "  4750K .......... .......... .......... .......... .......... 41% 1.63M 2s\n",
      "  4800K .......... .......... .......... .......... .......... 41% 1.51M 2s\n",
      "  4850K .......... .......... .......... .......... .......... 42%  869K 2s\n",
      "  4900K .......... .......... .......... .......... .......... 42%  728K 2s\n",
      "  4950K .......... .......... .......... .......... .......... 43% 2.86M 2s\n",
      "  5000K .......... .......... .......... .......... .......... 43% 1.58M 2s\n",
      "  5050K .......... .......... .......... .......... .......... 43% 4.15M 2s\n",
      "  5100K .......... .......... .......... .......... .......... 44% 1.80M 2s\n",
      "  5150K .......... .......... .......... .......... .......... 44%  809K 2s\n",
      "  5200K .......... .......... .......... .......... .......... 45% 2.60M 2s\n",
      "  5250K .......... .......... .......... .......... .......... 45% 1.83M 2s\n",
      "  5300K .......... .......... .......... .......... .......... 46% 4.13M 2s\n",
      "  5350K .......... .......... .......... .......... .......... 46% 5.53M 2s\n",
      "  5400K .......... .......... .......... .......... .......... 46% 4.13M 2s\n",
      "  5450K .......... .......... .......... .......... .......... 47% 5.29M 2s\n",
      "  5500K .......... .......... .......... .......... .......... 47% 4.25M 2s\n",
      "  5550K .......... .......... .......... .......... .......... 48% 7.74M 2s\n",
      "  5600K .......... .......... .......... .......... .......... 48% 3.27M 2s\n",
      "  5650K .......... .......... .......... .......... .......... 49%  589K 2s\n",
      "  5700K .......... .......... .......... .......... .......... 49%  943K 2s\n",
      "  5750K .......... .......... .......... .......... .......... 50%  826K 2s\n",
      "  5800K .......... .......... .......... .......... .......... 50% 3.40M 2s\n",
      "  5850K .......... .......... .......... .......... .......... 50%  172K 2s\n",
      "  5900K .......... .......... .......... .......... .......... 51% 3.80M 2s\n",
      "  5950K .......... .......... .......... .......... .......... 51% 1.88M 2s\n",
      "  6000K .......... .......... .......... .......... .......... 52% 3.53M 2s\n",
      "  6050K .......... .......... .......... .......... .......... 52% 4.81M 2s\n",
      "  6100K .......... .......... .......... .......... .......... 53% 4.34M 2s\n",
      "  6150K .......... .......... .......... .......... .......... 53% 7.31M 2s\n",
      "  6200K .......... .......... .......... .......... .......... 53% 3.20M 2s\n",
      "  6250K .......... .......... .......... .......... .......... 54% 4.55M 2s\n",
      "  6300K .......... .......... .......... .......... .......... 54% 4.23M 2s\n",
      "  6350K .......... .......... .......... .......... .......... 55% 5.56M 2s\n",
      "  6400K .......... .......... .......... .......... .......... 55% 3.15M 2s\n",
      "  6450K .......... .......... .......... .......... .......... 56% 4.24M 2s\n",
      "  6500K .......... .......... .......... .......... .......... 56% 6.61M 2s\n",
      "  6550K .......... .......... .......... .......... .......... 56% 4.27M 2s\n",
      "  6600K .......... .......... .......... .......... .......... 57% 3.98M 2s\n",
      "  6650K .......... .......... .......... .......... .......... 57% 7.26M 2s\n",
      "  6700K .......... .......... .......... .......... .......... 58% 3.66M 2s\n",
      "  6750K .......... .......... .......... .......... .......... 58% 5.01M 2s\n",
      "  6800K .......... .......... .......... .......... .......... 59% 6.19M 2s\n",
      "  6850K .......... .......... .......... .......... .......... 59% 4.27M 2s\n",
      "  6900K .......... .......... .......... .......... .......... 59% 5.94M 2s\n",
      "  6950K .......... .......... .......... .......... .......... 60% 2.72M 2s\n",
      "  7000K .......... .......... .......... .......... .......... 60% 4.26M 2s\n",
      "  7050K .......... .......... .......... .......... .......... 61%  919K 2s\n",
      "  7100K .......... .......... .......... .......... .......... 61% 6.17M 2s\n",
      "  7150K .......... .......... .......... .......... .......... 62% 1.80M 2s\n",
      "  7200K .......... .......... .......... .......... .......... 62% 3.91M 2s\n",
      "  7250K .......... .......... .......... .......... .......... 62% 2.66M 2s\n",
      "  7300K .......... .......... .......... .......... .......... 63% 1.86M 2s\n",
      "  7350K .......... .......... .......... .......... .......... 63% 3.50M 2s\n",
      "  7400K .......... .......... .......... .......... .......... 64% 4.71M 2s\n",
      "  7450K .......... .......... .......... .......... .......... 64% 1.86M 2s\n",
      "  7500K .......... .......... .......... .......... .......... 65% 1.95M 2s\n",
      "  7550K .......... .......... .......... .......... .......... 65% 8.21M 2s\n",
      "  7600K .......... .......... .......... .......... .......... 65% 2.86M 2s\n",
      "  7650K .......... .......... .......... .......... .......... 66% 8.12M 1s\n",
      "  7700K .......... .......... .......... .......... .......... 66% 5.34M 1s\n",
      "  7750K .......... .......... .......... .......... .......... 67% 3.65M 1s\n",
      "  7800K .......... .......... .......... .......... .......... 67% 7.92M 1s\n",
      "  7850K .......... .......... .......... .......... .......... 68% 5.48M 1s\n",
      "  7900K .......... .......... .......... .......... .......... 68% 2.63M 1s\n",
      "  7950K .......... .......... .......... .......... .......... 68% 9.37M 1s\n",
      "  8000K .......... .......... .......... .......... .......... 69% 1.70M 1s\n",
      "  8050K .......... .......... .......... .......... .......... 69% 4.20M 1s\n",
      "  8100K .......... .......... .......... .......... .......... 70% 3.01M 1s\n",
      "  8150K .......... .......... .......... .......... .......... 70%  439K 1s\n",
      "  8200K .......... .......... .......... .......... .......... 71% 3.54M 1s\n",
      "  8250K .......... .......... .......... .......... .......... 71% 1.38M 1s\n",
      "  8300K .......... .......... .......... .......... .......... 72% 3.36M 1s\n",
      "  8350K .......... .......... .......... .......... .......... 72% 2.52M 1s\n",
      "  8400K .......... .......... .......... .......... .......... 72% 1.31M 1s\n",
      "  8450K .......... .......... .......... .......... .......... 73% 3.68M 1s\n",
      "  8500K .......... .......... .......... .......... .......... 73% 4.65M 1s\n",
      "  8550K .......... .......... .......... .......... .......... 74% 2.20M 1s\n",
      "  8600K .......... .......... .......... .......... .......... 74%  182K 1s\n",
      "  8650K .......... .......... .......... .......... .......... 75% 10.8M 1s\n",
      "  8700K .......... .......... .......... .......... .......... 75% 47.5M 1s\n",
      "  8750K .......... .......... .......... .......... .......... 75% 48.9M 1s\n",
      "  8800K .......... .......... .......... .......... .......... 76% 39.3M 1s\n",
      "  8850K .......... .......... .......... .......... .......... 76% 51.7M 1s\n",
      "  8900K .......... .......... .......... .......... .......... 77% 6.41M 1s\n",
      "  8950K .......... .......... .......... .......... .......... 77% 6.41M 1s\n",
      "  9000K .......... .......... .......... .......... .......... 78% 2.19M 1s\n",
      "  9050K .......... .......... .......... .......... .......... 78% 1.64M 1s\n",
      "  9100K .......... .......... .......... .......... .......... 78%  783K 1s\n",
      "  9150K .......... .......... .......... .......... .......... 79% 4.54M 1s\n",
      "  9200K .......... .......... .......... .......... .......... 79% 4.95M 1s\n",
      "  9250K .......... .......... .......... .......... .......... 80% 3.72M 1s\n",
      "  9300K .......... .......... .......... .......... .......... 80% 2.42M 1s\n",
      "  9350K .......... .......... .......... .......... .......... 81% 6.95M 1s\n",
      "  9400K .......... .......... .......... .......... .......... 81% 6.16M 1s\n",
      "  9450K .......... .......... .......... .......... .......... 81% 4.27M 1s\n",
      "  9500K .......... .......... .......... .......... .......... 82% 3.47M 1s\n",
      "  9550K .......... .......... .......... .......... .......... 82% 8.69M 1s\n",
      "  9600K .......... .......... .......... .......... .......... 83% 2.84M 1s\n",
      "  9650K .......... .......... .......... .......... .......... 83% 6.15M 1s\n",
      "  9700K .......... .......... .......... .......... .......... 84% 7.94M 1s\n",
      "  9750K .......... .......... .......... .......... .......... 84% 3.98M 1s\n",
      "  9800K .......... .......... .......... .......... .......... 84% 7.87M 1s\n",
      "  9850K .......... .......... .......... .......... .......... 85% 6.63M 1s\n",
      "  9900K .......... .......... .......... .......... .......... 85% 4.62M 1s\n",
      "  9950K .......... .......... .......... .......... .......... 86% 8.47M 1s\n",
      " 10000K .......... .......... .......... .......... .......... 86% 5.11M 1s\n",
      " 10050K .......... .......... .......... .......... .......... 87%  478K 1s\n",
      " 10100K .......... .......... .......... .......... .......... 87% 1.45M 1s\n",
      " 10150K .......... .......... .......... .......... .......... 87% 5.73M 1s\n",
      " 10200K .......... .......... .......... .......... .......... 88% 4.31M 1s\n",
      " 10250K .......... .......... .......... .......... .......... 88% 6.60M 1s\n",
      " 10300K .......... .......... .......... .......... .......... 89% 7.02M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 89% 4.27M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 90% 3.17M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 90% 3.47M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 90% 3.46M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 91% 7.49M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 91% 4.75M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 92% 7.97M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 92% 4.46M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 93% 9.19M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 93% 2.93M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 93% 5.22M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 94% 4.44M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 94% 7.96M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 95% 7.12M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 95% 3.85M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 96% 7.12M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 96% 5.77M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 97% 2.93M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 97% 3.29M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 97% 6.22M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 98% 5.10M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 98% 5.47M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 99% 4.68M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 99% 3.37M 0s\n",
      " 11550K .......... .......... .......... .......... ......    100% 9.12M=4.4s\n",
      "\n",
      "2018-12-06 23:58:04 (2.58 MB/s) - ‘primer-dataset.json’ saved [11874761/11874761]\n",
      "\n",
      "2018-12-06T23:58:04.722+0000\tconnected to: localhost\n",
      "2018-12-06T23:58:04.722+0000\tdropping: mongo_lab.restaurants\n",
      "2018-12-06T23:58:06.085+0000\timported 25359 documents\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Use wget to download the data\n",
    "wget https://raw.githubusercontent.com/mongodb/docs-assets/primer-dataset/primer-dataset.json\n",
    "# mongoimport is the Mongo command to import data.  \n",
    "# It specifies the database, collection and format, and import file\n",
    "# --drop means it's going to drop any collection with the same name which already exists\n",
    "mongoimport --db mongo_lab --collection restaurants --drop --file ./primer-dataset.json\n",
    "# Delete the JSON file we just downloaded\n",
    "rm ./primer-dataset.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the variable `collection` to refer to the new collection `restaurants`, and inspect the general format of the data by adding the code below to find the first record of the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "collection = db.restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw the [`collection.find()`](https://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.find) function earlier to return all the documents we inserted into our `test` collection.  Without any arguments, `find()` will return a cursor of all the available documents from in the collection.  To refine queries, however, the search can be filtered by the addition of a first parameter.\n",
    "\n",
    "The `filter` parameter is a dict, which searches for the documents where `key` = `value` where the dict is of the form `{key: value}`.  For example, to find all bakeries in the city, we would do the following query:   \n",
    "\n",
    "**WARNING** Unlike the Mongo command line interface, if you try and print the output of a `find()` query, it will continue to output all results until it has finished.  This can cause the browser to crash, particularly if it is a particularly large query set.\n",
    "\n",
    "Using `find().count()` is a useful way of checking how many a result will return, and `find_one()` to see the general structure of a result. If you use `find()`, make sure you either include the `limit` argument, or have a counter or other condition to break out of your printing loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5c09b78cd8c8b5898b20c861'),\n",
      " 'address': {'building': '1007',\n",
      "             'coord': [-73.856077, 40.848447],\n",
      "             'street': 'Morris Park Ave',\n",
      "             'zipcode': '10462'},\n",
      " 'borough': 'Bronx',\n",
      " 'cuisine': 'Bakery',\n",
      " 'grades': [{'date': datetime.datetime(2014, 3, 3, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 2},\n",
      "            {'date': datetime.datetime(2013, 9, 11, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 6},\n",
      "            {'date': datetime.datetime(2013, 1, 24, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 10},\n",
      "            {'date': datetime.datetime(2011, 11, 23, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 9},\n",
      "            {'date': datetime.datetime(2011, 3, 10, 0, 0),\n",
      "             'grade': 'B',\n",
      "             'score': 14}],\n",
      " 'name': 'Morris Park Bake Shop',\n",
      " 'restaurant_id': '30075445'}\n",
      "{'_id': ObjectId('5c09b78cd8c8b5898b20c879'),\n",
      " 'address': {'building': '120',\n",
      "             'coord': [-73.9998042, 40.7251256],\n",
      "             'street': 'Prince Street',\n",
      "             'zipcode': '10012'},\n",
      " 'borough': 'Manhattan',\n",
      " 'cuisine': 'Bakery',\n",
      " 'grades': [{'date': datetime.datetime(2014, 10, 17, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 11},\n",
      "            {'date': datetime.datetime(2013, 9, 18, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 13},\n",
      "            {'date': datetime.datetime(2013, 4, 30, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 7},\n",
      "            {'date': datetime.datetime(2012, 4, 20, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 7},\n",
      "            {'date': datetime.datetime(2011, 12, 19, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 3}],\n",
      " 'name': \"Olive'S\",\n",
      " 'restaurant_id': '40363151'}\n",
      "{'_id': ObjectId('5c09b78cd8c8b5898b20c9b8'),\n",
      " 'address': {'building': '267',\n",
      "             'coord': [-73.933605, 40.669476],\n",
      "             'street': 'Schenectady Avenue',\n",
      "             'zipcode': '11213'},\n",
      " 'borough': 'Brooklyn',\n",
      " 'cuisine': 'Bakery',\n",
      " 'grades': [{'date': datetime.datetime(2014, 3, 18, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 2},\n",
      "            {'date': datetime.datetime(2013, 10, 3, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 13},\n",
      "            {'date': datetime.datetime(2012, 9, 26, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 13},\n",
      "            {'date': datetime.datetime(2011, 10, 13, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 7}],\n",
      " 'name': 'Tropical House Baking Co.',\n",
      " 'restaurant_id': '40372596'}\n",
      "{'_id': ObjectId('5c09b78cd8c8b5898b20ca80'),\n",
      " 'address': {'building': '70',\n",
      "             'coord': [-73.975144, 40.675441],\n",
      "             'street': '7 Avenue',\n",
      "             'zipcode': '11217'},\n",
      " 'borough': 'Brooklyn',\n",
      " 'cuisine': 'Bakery',\n",
      " 'grades': [{'date': datetime.datetime(2014, 11, 26, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 9},\n",
      "            {'date': datetime.datetime(2013, 12, 11, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 11},\n",
      "            {'date': datetime.datetime(2012, 12, 7, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 9},\n",
      "            {'date': datetime.datetime(2011, 12, 20, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12}],\n",
      " 'name': \"Cousin John'S Cafe And Bakery\",\n",
      " 'restaurant_id': '40383763'}\n",
      "{'_id': ObjectId('5c09b78cd8c8b5898b20ca99'),\n",
      " 'address': {'building': '2169',\n",
      "             'coord': [-73.90539919999999, 40.7730596],\n",
      "             'street': 'Steinway Street',\n",
      "             'zipcode': '11105'},\n",
      " 'borough': 'Queens',\n",
      " 'cuisine': 'Bakery',\n",
      " 'grades': [{'date': datetime.datetime(2014, 10, 23, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 7},\n",
      "            {'date': datetime.datetime(2013, 10, 3, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12},\n",
      "            {'date': datetime.datetime(2013, 5, 18, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12},\n",
      "            {'date': datetime.datetime(2012, 12, 5, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 11},\n",
      "            {'date': datetime.datetime(2012, 6, 14, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 9},\n",
      "            {'date': datetime.datetime(2011, 11, 29, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 8}],\n",
      " 'name': 'Victory Sweet Shop',\n",
      " 'restaurant_id': '40384920'}\n"
     ]
    }
   ],
   "source": [
    "for doc in collection.find({'cuisine': 'Bakery'}).limit(5):\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noted, count() is deprecated in the MongoDb drivers compatible with the 4.0features, as a result, we should use countDocuments() in the following exercises. (for more information, check https://docs.mongodb.com/manual/reference/method/db.collection.count/ and http://api.mongodb.com/python/current/changelog.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count_documents({'cuisine': 'Bakery'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A filter can have as many conditions as you like, and will assume that you are using an AND condition, unless you specify otherwise (as below).  In the cell below, write a query to return the number/count of all the establishments with a cuisine of `Hamburgers` in the borough of Manhattan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# All establishments with: \n",
    "# * a cuisine of 'Hamburgers' \n",
    "# * in the borough of 'Manhattan\n",
    "\n",
    "collection.count_documents({'cuisine': 'Hamburgers', 'borough':'Manhattan'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hamburgers',\n",
       " 'Irish',\n",
       " 'Jewish/Kosher',\n",
       " 'American',\n",
       " 'Delicatessen',\n",
       " 'Ice Cream, Gelato, Yogurt, Ices',\n",
       " 'Chinese',\n",
       " 'Bakery',\n",
       " 'Chicken',\n",
       " 'Caribbean',\n",
       " 'Turkish',\n",
       " 'Donuts',\n",
       " 'Sandwiches/Salads/Mixed Buffet',\n",
       " 'Bagels/Pretzels',\n",
       " 'Pizza',\n",
       " 'Continental',\n",
       " 'Italian',\n",
       " 'Latin (Cuban, Dominican, Puerto Rican, South & Central American)',\n",
       " 'Polish',\n",
       " 'German',\n",
       " 'Steak',\n",
       " 'French',\n",
       " 'Pizza/Italian',\n",
       " 'Mexican',\n",
       " 'Spanish',\n",
       " 'Café/Coffee/Tea',\n",
       " 'Tex-Mex',\n",
       " 'Pancakes/Waffles',\n",
       " 'Soul Food',\n",
       " 'Seafood',\n",
       " 'Hotdogs',\n",
       " 'Greek',\n",
       " 'African',\n",
       " 'Not Listed/Not Applicable',\n",
       " 'Japanese',\n",
       " 'Indian',\n",
       " 'Armenian',\n",
       " 'Thai',\n",
       " 'Chinese/Cuban',\n",
       " 'Mediterranean',\n",
       " 'Korean',\n",
       " 'Bottled beverages, including water, sodas, juices, etc.',\n",
       " 'Russian',\n",
       " 'Eastern European',\n",
       " 'Middle Eastern',\n",
       " 'Asian',\n",
       " 'Ethiopian',\n",
       " 'Vegetarian',\n",
       " 'Barbecue',\n",
       " 'Egyptian',\n",
       " 'English',\n",
       " 'Other',\n",
       " 'Sandwiches',\n",
       " 'Portuguese',\n",
       " 'Indonesian',\n",
       " 'Chinese/Japanese',\n",
       " 'Filipino',\n",
       " 'Juice, Smoothies, Fruit Salads',\n",
       " 'Brazilian',\n",
       " 'Afghan',\n",
       " 'Vietnamese/Cambodian/Malaysia',\n",
       " 'CafÃ©/Coffee/Tea',\n",
       " 'Soups & Sandwiches',\n",
       " 'Tapas',\n",
       " 'Moroccan',\n",
       " 'Pakistani',\n",
       " 'Peruvian',\n",
       " 'Bangladeshi',\n",
       " 'Czech',\n",
       " 'Salads',\n",
       " 'Creole',\n",
       " 'Fruits/Vegetables',\n",
       " 'Iranian',\n",
       " 'Cajun',\n",
       " 'Scandinavian',\n",
       " 'Polynesian',\n",
       " 'Soups',\n",
       " 'Australian',\n",
       " 'Hotdogs/Pretzels',\n",
       " 'Southwestern',\n",
       " 'Nuts/Confectionary',\n",
       " 'Hawaiian',\n",
       " 'Creole/Cajun',\n",
       " 'Californian',\n",
       " 'Chilean']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.distinct('cuisine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-documents\n",
    "\n",
    "A valid JSON style \"document\" can have another JSON document inside it.  To access these, we use the \"dot\" notation to access them.  For example, to get all the restaurants in a certain zipcode, you would run code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address': {'zipcode': '10462'}}\n",
      "{'address': {'zipcode': '10462'}}\n",
      "{'address': {'zipcode': '10462'}}\n",
      "{'address': {'zipcode': '10462'}}\n",
      "{'address': {'zipcode': '10462'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "cursor = collection.find({'address.zipcode': '10462'}, {'address.zipcode': 1, '_id':0}).limit(5)\n",
    "for c in cursor:\n",
    "    pprint(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators\n",
    "\n",
    "MongoDB has a series of [operators](https://docs.mongodb.com/manual/reference/operator/query/) which allow us to do more sophisticated filters on our queries.  There are too many to go into individually, but we will look at a few important ones.  The specific syntax varies depending on the operator, so it isn't possible to give a general rule, but we will go over a few examples here.  Make sure you check the [documentation](https://docs.mongodb.com/manual/reference/operator/query/) for use on each one.\n",
    "\n",
    "#### [\\$or](https://docs.mongodb.com/manual/reference/operator/query/or/#op._S_or)\n",
    "\n",
    "Performs a logical **OR** operation on all the key/value pairs in a list, as in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Camaradas El Barrio'}\n",
      "{'name': 'Makana'}\n"
     ]
    }
   ],
   "source": [
    "filter = {\"$or\": [{\"cuisine\": \"Polynesian\"}, {\"cuisine\": \"Hawaiian\"}]}\n",
    "for f in collection.find(filter, {'name': 1, '_id': 0}).limit(2):\n",
    "    pprint(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [`$regex`](https://docs.mongodb.com/manual/reference/operator/query/regex/#op._S_regex)\n",
    "\n",
    "The `$regex` operator searches for a regular expression on a particular field.  Within the filter field, the named field (a key) takes a dict as a value.  \n",
    "\n",
    "For example, to search for all restaurants which start with the word \"Pretzel\" in the title you can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = {\"name\": {\"$regex\": '^Pretzel'}}\n",
    "collection.count_documents(filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways to use regular expressions in PyMongo, you can use the [`re`](https://docs.python.org/3/library/re.html) module in Python.  In Mongo itself, you can use the following syntax: The simplest is to enclose the regular expression inside `/` characters, as in `{\"name\": /^Pretzel/}`, but that doesn't work properly in PyMongo.\n",
    "\n",
    "Using the `$regex` operator, find all restaurants which end in \"Bar\" in the borough of Brooklyn.\n",
    "\n",
    "HINT: The regex character for the end of a string is `$`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "filter_regex = {\"name\": {\"$regex\": \"Bar$\"}}\n",
    "\n",
    "collection.count_documents(filter_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [`$gt`](https://docs.mongodb.com/manual/reference/operator/query/gt/#op._S_gt)\n",
    "\n",
    "The `$gt` operator is a comparison between two values where one is greater than the other.  \n",
    "\n",
    "For example, consider this code which finds restaurants which have had a score of more than 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = {'grades.score': {'$gt': 12}}\n",
    "collection.count_documents(filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using one of the other comparison operators, find all restaurants which had a grade awarded on the 15 December 2012.  You'll need to create a [`datetime`](https://docs.python.org/2/library/datetime.html#datetime-objects) object in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'grades': [{'date': datetime.datetime(2014, 8, 5, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 10},\n",
      "            {'date': datetime.datetime(2014, 2, 5, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12},\n",
      "            {'date': datetime.datetime(2012, 12, 15, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12},\n",
      "            {'date': datetime.datetime(2011, 11, 23, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12}],\n",
      " 'name': 'Ajanta India'}\n",
      "{'grades': [{'date': datetime.datetime(2014, 12, 16, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 4},\n",
      "            {'date': datetime.datetime(2013, 12, 23, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 9},\n",
      "            {'date': datetime.datetime(2012, 12, 15, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 10}],\n",
      " 'name': 'Internationalhouse'}\n",
      "{'grades': [{'date': datetime.datetime(2015, 1, 14, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 6},\n",
      "            {'date': datetime.datetime(2013, 12, 17, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 2},\n",
      "            {'date': datetime.datetime(2012, 12, 15, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12},\n",
      "            {'date': datetime.datetime(2012, 5, 15, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 7}],\n",
      " 'name': \"Mike'S Pizza Dannys\"}\n",
      "{'grades': [{'date': datetime.datetime(2014, 8, 15, 0, 0),\n",
      "             'grade': 'B',\n",
      "             'score': 14},\n",
      "            {'date': datetime.datetime(2014, 2, 26, 0, 0),\n",
      "             'grade': 'B',\n",
      "             'score': 23},\n",
      "            {'date': datetime.datetime(2012, 12, 15, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 9},\n",
      "            {'date': datetime.datetime(2011, 11, 29, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12}],\n",
      " 'name': 'Sushi Yama'}\n",
      "{'grades': [{'date': datetime.datetime(2014, 9, 10, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 10},\n",
      "            {'date': datetime.datetime(2014, 1, 29, 0, 0),\n",
      "             'grade': 'B',\n",
      "             'score': 23},\n",
      "            {'date': datetime.datetime(2013, 7, 19, 0, 0),\n",
      "             'grade': 'C',\n",
      "             'score': 30},\n",
      "            {'date': datetime.datetime(2012, 12, 15, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 13},\n",
      "            {'date': datetime.datetime(2012, 5, 7, 0, 0),\n",
      "             'grade': 'C',\n",
      "             'score': 31},\n",
      "            {'date': datetime.datetime(2011, 10, 1, 0, 0),\n",
      "             'grade': 'B',\n",
      "             'score': 22}],\n",
      " 'name': 'La Tortilleria Mexicana Los Tres Hermanos'}\n",
      "{'grades': [{'date': datetime.datetime(2014, 5, 7, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 9},\n",
      "            {'date': datetime.datetime(2013, 5, 8, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 7},\n",
      "            {'date': datetime.datetime(2012, 12, 15, 0, 0),\n",
      "             'grade': 'C',\n",
      "             'score': 29},\n",
      "            {'date': datetime.datetime(2011, 12, 19, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 7},\n",
      "            {'date': datetime.datetime(2011, 8, 9, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 8}],\n",
      " 'name': 'Outback Steakhouse 3332'}\n",
      "{'grades': [{'date': datetime.datetime(2015, 1, 7, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 13},\n",
      "            {'date': datetime.datetime(2014, 8, 26, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 10},\n",
      "            {'date': datetime.datetime(2014, 1, 30, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 13},\n",
      "            {'date': datetime.datetime(2013, 8, 1, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 4},\n",
      "            {'date': datetime.datetime(2012, 12, 15, 0, 0),\n",
      "             'grade': 'B',\n",
      "             'score': 22},\n",
      "            {'date': datetime.datetime(2012, 4, 3, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12}],\n",
      " 'name': \"Jj'S Jamaican Restaurant\"}\n",
      "{'grades': [{'date': datetime.datetime(2014, 10, 1, 0, 0),\n",
      "             'grade': 'C',\n",
      "             'score': 55},\n",
      "            {'date': datetime.datetime(2014, 4, 21, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 13},\n",
      "            {'date': datetime.datetime(2012, 12, 15, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 12},\n",
      "            {'date': datetime.datetime(2012, 5, 22, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 11},\n",
      "            {'date': datetime.datetime(2012, 2, 1, 0, 0),\n",
      "             'grade': 'C',\n",
      "             'score': 49}],\n",
      " 'name': 'Sushi Tatsu'}\n",
      "{'grades': [{'date': datetime.datetime(2014, 12, 4, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 13},\n",
      "            {'date': datetime.datetime(2013, 12, 3, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 9},\n",
      "            {'date': datetime.datetime(2013, 6, 5, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 4},\n",
      "            {'date': datetime.datetime(2012, 12, 15, 0, 0),\n",
      "             'grade': 'A',\n",
      "             'score': 13}],\n",
      " 'name': 'Soco Restaurant'}\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "import datetime\n",
    "\n",
    "date_to_filter = datetime.datetime(2012, 12, 15)\n",
    "\n",
    "for doc in collection.find({'grades.date': date_to_filter}, {'_id': 0, 'grades': 1, 'name': 1}):\n",
    "    pprint (doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organising output\n",
    "\n",
    "So far, we have seen the two of the arguments in the `find()` and related functions.  The `filter` which allows us to select the criteria for documents in the collection, and the `limit` to limit the amount of results.  You should read the documentation fully about the function in your own time, but for now, we will go over two other arguments which are for organising output: field selection, and sorting.\n",
    "\n",
    "The field selection or `projection` argument is the argument after the \\[optional\\] filter, and is either:\n",
    "\n",
    "* A list of fields to include (plus \\_id)\n",
    "* A dict of fields with True/False to include\n",
    "\n",
    "For example, to display only the name of the restaurant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Churrascaria Plataforma'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = {'cuisine': 'Brazilian'}\n",
    "fields = {'_id': False, 'name': True}\n",
    "collection.find_one(filter, fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sort argument is a dict object of field names as keys, and directions.  This can be done either as a named parameter when calling `find()`, or as a function in its own right [`sort()`](https://api.mongodb.com/python/current/api/pymongo/cursor.html#pymongo.cursor.Cursor.sort)\n",
    "\n",
    "For example, to sort in alphabetical order, consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Barzinho'}\n",
      "{'name': 'Beco'}\n",
      "{'name': 'Beija-Flor'}\n",
      "{'name': 'Berimbau'}\n",
      "{'name': 'Brazil Brazil Restuarant'}\n",
      "{'name': 'Brazil Grill'}\n",
      "{'name': 'Buffet 58'}\n",
      "{'name': 'Carioca Grill'}\n",
      "{'name': 'Casa'}\n",
      "{'name': 'Churrascaria Plataforma'}\n",
      "{'name': 'Circus Restaurant'}\n",
      "{'name': 'Copacabana Pizza & Grill'}\n",
      "{'name': 'Emporium Brasil Restaurant'}\n",
      "{'name': 'Esperanto'}\n",
      "{'name': 'Fogo De Chao'}\n",
      "{'name': 'Malagueta  Restaurant'}\n",
      "{'name': 'Miss Favela'}\n",
      "{'name': 'Pacificos Fine Foods'}\n",
      "{'name': 'Point Brazil'}\n",
      "{'name': 'Rainhas'}\n",
      "{'name': 'Rice & Beans Restaurant'}\n",
      "{'name': 'Sao Restaurant'}\n",
      "{'name': 'Texas De Brazil Churrascaria'}\n",
      "{'name': 'Via Brazil'}\n",
      "{'name': 'Villa Brazil Cafe Grill'}\n",
      "{'name': 'Zebu Grill'}\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "# The ASCENDING and DESCENDING constants have values of 1 (ASCENDING) and -1 (DESCENDING)\n",
    "sort = [('name', pymongo.ASCENDING)]\n",
    "for d in collection.find(filter, projection=fields, sort=sort):\n",
    "    pprint(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB Aggregation Framework\n",
    "\n",
    "The most common usage for the aggregation framework is to perform group operations such as sum, count or average.  The framework works as a pipeline, with a series of different stages where the data are transformed in each one.\n",
    "\n",
    "At its simplest, this can be used to obtain output like min, max, count, avg on a collection as follows:\n",
    "\n",
    "[link](https://docs.mongodb.com/manual/reference/operator/aggregation/group/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': None, 'size': 25359, 'min': '30075445', 'max': '50018995'}\n"
     ]
    }
   ],
   "source": [
    "group = {\n",
    "    '$group': {\n",
    "        '_id': None, \n",
    "        'size': {'$sum': 1},\n",
    "        'min': {'$min': '$restaurant_id'},\n",
    "        'max': {'$max': '$restaurant_id'}\n",
    "    }\n",
    "}\n",
    "\n",
    "cursor = collection.aggregate([group])\n",
    "for c in cursor:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it has an `$_id: None` key/value pair in it.  It is compulsory for a `$group` pipeline to have one, and it indicates what it is grouping by.  In this case, we haven't grouped it at all, however it can also be used for more complex output where documents are grouped according to a field.\n",
    "\n",
    "### Aggregation example\n",
    "\n",
    "Consider this example, of finding the breakdown of how many of each type of restaurant there is in the Bronx.  We would need to go through the following stages:\n",
    "\n",
    "- Identify restaurants which are in the Bronx\n",
    "- Group the restaurants by type to get the count\n",
    "- Sort the results in a sensible way\n",
    "\n",
    "The code to perform this query is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'American', 'count': 411}\n",
      "{'_id': 'Chinese', 'count': 323}\n",
      "{'_id': 'Pizza', 'count': 197}\n",
      "{'_id': 'Latin (Cuban, Dominican, Puerto Rican, South & Central American)', 'count': 187}\n",
      "{'_id': 'Spanish', 'count': 127}\n",
      "{'_id': 'Caribbean', 'count': 110}\n",
      "{'_id': 'Chicken', 'count': 108}\n"
     ]
    }
   ],
   "source": [
    "# Restrict the results to only establishments in the Bronx.  \n",
    "# '$match' indicates the stage in the pipeline, and the dictionary is the same as using with find()\n",
    "match = {\n",
    "    \"$match\": {\"borough\": \"Bronx\"}\n",
    "}\n",
    "\n",
    "# $group indicates the stage in the pipeline\n",
    "# _id is the field to perform the operation on (like SQL GROUP BY)\n",
    "# count is the name of the field that the result will be in\n",
    "# $sum is the counting operation, and the value 1 is how many to count each time\n",
    "group = {\n",
    "    '$group': {'_id': '$cuisine', 'count': {'$sum': 1}}\n",
    "    \n",
    "}\n",
    "# $sort indicates the position in the pipeline\n",
    "# count is the field to sort by, and -1 means to sort in descending order\n",
    "sort = {\n",
    "    '$sort': {'count': pymongo.DESCENDING}\n",
    "}\n",
    "\n",
    "match_final = {\n",
    "    \"$match\": {\"count\": {\"$gt\": 100}}\n",
    "}\n",
    "\n",
    "cursor = collection.aggregate([match, group, sort, match_final])\n",
    "for c in cursor:\n",
    "    print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple query, which shows some of the basic stages of the aggregation pipeline.  It can be improved as follows:\n",
    "\n",
    "* We can change the name of the `_id` in the output back to `cuisine` using the `$project` stage\n",
    "* We can change the order of the output to be sorted in alphabetical order as well\n",
    "* We can limit the results to include results only with a count of 20 or more\n",
    "\n",
    "Implement those stages in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'African', 'count': 31, 'cuisine': 'African'}\n",
      "{'_id': 'American', 'count': 411, 'cuisine': 'American'}\n",
      "{'_id': 'Bakery', 'count': 71, 'cuisine': 'Bakery'}\n",
      "{'_id': 'Café/Coffee/Tea', 'count': 45, 'cuisine': 'Café/Coffee/Tea'}\n",
      "{'_id': 'Caribbean', 'count': 110, 'cuisine': 'Caribbean'}\n",
      "{'_id': 'Chicken', 'count': 108, 'cuisine': 'Chicken'}\n",
      "{'_id': 'Chinese', 'count': 323, 'cuisine': 'Chinese'}\n",
      "{'_id': 'Delicatessen', 'count': 26, 'cuisine': 'Delicatessen'}\n",
      "{'_id': 'Donuts', 'count': 68, 'cuisine': 'Donuts'}\n",
      "{'_id': 'Hamburgers', 'count': 78, 'cuisine': 'Hamburgers'}\n",
      "{'_id': 'Ice Cream, Gelato, Yogurt, Ices', 'count': 27, 'cuisine': 'Ice Cream, Gelato, Yogurt, Ices'}\n",
      "{'_id': 'Italian', 'count': 52, 'cuisine': 'Italian'}\n",
      "{'_id': 'Juice, Smoothies, Fruit Salads', 'count': 35, 'cuisine': 'Juice, Smoothies, Fruit Salads'}\n",
      "{'_id': 'Latin (Cuban, Dominican, Puerto Rican, South & Central American)', 'count': 187, 'cuisine': 'Latin (Cuban, Dominican, Puerto Rican, South & Central American)'}\n",
      "{'_id': 'Mexican', 'count': 89, 'cuisine': 'Mexican'}\n",
      "{'_id': 'Other', 'count': 86, 'cuisine': 'Other'}\n",
      "{'_id': 'Pizza', 'count': 197, 'cuisine': 'Pizza'}\n",
      "{'_id': 'Pizza/Italian', 'count': 53, 'cuisine': 'Pizza/Italian'}\n",
      "{'_id': 'Sandwiches', 'count': 49, 'cuisine': 'Sandwiches'}\n",
      "{'_id': 'Seafood', 'count': 26, 'cuisine': 'Seafood'}\n",
      "{'_id': 'Spanish', 'count': 127, 'cuisine': 'Spanish'}\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "project_stage = {\n",
    "    \"$project\": {\"cuisine\": \"$_id\", \"count\": 1}\n",
    "}\n",
    "\n",
    "sort_stage = {\n",
    "    \"$sort\": {\"cuisine\": pymongo.ASCENDING}\n",
    "}\n",
    "\n",
    "match_stage = {\n",
    "    \"$match\": {\"count\": {\"$gt\":20} }\n",
    "}\n",
    "\n",
    "pipeline = [match, group, project_stage, match_stage, sort_stage] #More code here...\n",
    "cursor = collection.aggregate(pipeline)\n",
    "for c in cursor:\n",
    "    print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detour: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE FOR sort\n",
    "\n",
    "pipeline.append(sort)\n",
    "cursor = collection.aggregate(pipeline)\n",
    "for c in cursor:\n",
    "    pprint(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE FOR `count` > 20\n",
    "\n",
    "cursor = collection.aggregate(pipeline)\n",
    "for c in cursor:\n",
    "    pprint(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "How would you work out the percentage of each type of cuisine out of all selected restaurants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where next?\n",
    "\n",
    "* Dealing with array data\n",
    "* Update, delete, and drop\n",
    "* Setting up authentication\n",
    "* Sharding databases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
