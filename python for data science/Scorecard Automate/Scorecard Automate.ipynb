{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scorecard Automation\n",
    "\n",
    "#### General Outline\n",
    "\n",
    "- First find **offset**\n",
    "- Check date\n",
    "- Read tables one by one\n",
    "- check for missing tables\n",
    "- Check data in each tabel\n",
    "- Check for missing data\n",
    "- Check if charts exist\n",
    "- Validate data with rnramd\n",
    "\n",
    "___\n",
    "\n",
    "**Write function to determine which sheet contains which data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of offsets\n",
    "\n",
    "> Network Summary Heading : 3\n",
    "\n",
    "> Bing O&O Core Browse:\n",
    "\n",
    "---\n",
    "\n",
    "**Make these global vars so that they can be changed anytime**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_offsets = [0, 21]\n",
    "\n",
    "y_offsets = [6, 6]\n",
    "widths = [7, 7]\n",
    "\n",
    "heights = [10, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Development mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print (platform.system())\n",
    "\n",
    "dev_mode = platform.system()\n",
    "\n",
    "if dev_mode == \"Linux\":\n",
    "    root_path = \"/media/shaunak/New Volume/my_projects/data science updated/python for data science/Scorecard Automate/data/\"\n",
    "elif dev_mode == \"Windows\":\n",
    "    root_path = \"D:/data_science-master/python for data science/Scorecard Automate/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             1       2       3     4       5       6\n",
      "0                                                   \n",
      "oRPM     72.81 -0.0228 -0.0254  None  0.1085  0.1562\n",
      "oPPC     92.5¢ -0.0106 -0.0194  None  0.0233  0.1022\n",
      "oCY      0.079 -0.0123 -0.0061  None  0.0833  0.0490\n",
      "oMLIY     0.56 -0.0251 -0.0093  None -0.0892 -0.1155\n",
      "oVol     117mm -0.0219  0.0063  None  0.0200  0.0417\n",
      "oRev   $8.52mm -0.0442 -0.0193  None  0.1306  0.2045\n",
      "Rev    $8.55mm -0.0442 -0.0190  None  0.1327  0.1995\n",
      "Vol      129mm -0.0437 -0.0092  None  0.0632  0.0795\n",
      "RPM      66.52 -0.0005 -0.0099  None  0.0651  0.1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor row in sheet_nw_sc.iter_rows(min_row=21,min_col=23, max_col=30, max_row=25):\\n    for cell in row:\\n        print cell.value\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import quandl\n",
    "import datetime\n",
    "\n",
    "wb = openpyxl.load_workbook(filename=root_path + 'data.xlsx', \n",
    "                   read_only=True)\n",
    "sheet_nw_sc = wb['Sheet4']\n",
    "\n",
    "data_rows = []\n",
    "for row in sheet_nw_sc['W10':'AC18']:\n",
    "    data_cols = []\n",
    "    for cell in row:\n",
    "        data_cols.append(cell.value)\n",
    "    data_rows.append(data_cols)\n",
    "\n",
    "    \n",
    "nw_sc_df = pd.DataFrame(data_rows)\n",
    "\n",
    "nw_sc_df.set_index(0, inplace=True)\n",
    "\n",
    "print (nw_sc_df)\n",
    "\n",
    "\"\"\"\n",
    "for row in sheet_nw_sc.iter_rows(min_row=21,min_col=23, max_col=30, max_row=25):\n",
    "    for cell in row:\n",
    "        print cell.value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the file + determining offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "offset to be changed\n",
      "Offset changed\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "\n",
    "base_cell = 'W3'\n",
    "\n",
    "network_sc_date_as_date = \"\"\n",
    "\n",
    "workbook = openpyxl.load_workbook(filename = root_path + 'data3.xlsx', \n",
    "                   read_only=True)\n",
    "\n",
    "network_sc_sheet = workbook['Sheet4']\n",
    "\n",
    "first_heading = str(network_sc_sheet['W3'].value)\n",
    "\n",
    "print (first_heading.strip('-'))\n",
    "\n",
    "\n",
    "if first_heading is None or first_heading.split('-')[0].strip() != 'SEARCH BG SCORECARD':\n",
    "    # print first_heading.split('-')[0].strip()\n",
    "    print (\"offset to be changed\")\n",
    "    \n",
    "    first_heading = str(network_sc_sheet['W14'].value)\n",
    "    \n",
    "    if first_heading.split('-')[0].strip() == 'SEARCH BG SCORECARD':\n",
    "        offset = 11\n",
    "        print (\"Offset changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offset changed at this step -- Move to separate function\n",
    "\n",
    "#### Validating the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W14\n",
      "January 3, 2018\n",
      "Scorecard is behind by:  37 days\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_date():\n",
    "    global offset\n",
    "    global base_cell\n",
    "    global network_sc_sheet\n",
    "    global network_sc_date_as_date\n",
    "    # base cell = W3\n",
    "    base_cell_num = int(base_cell[1:len(base_cell)])\n",
    "    base_cell_num += offset\n",
    "    \n",
    "    cell_ref = base_cell[0] + str(base_cell_num)\n",
    "    \n",
    "    print (cell_ref)\n",
    "    \n",
    "    # Modifying the base cell\n",
    "    \n",
    "    base_cell = cell_ref\n",
    "    \n",
    "    first_heading = network_sc_sheet[cell_ref].value\n",
    "    \n",
    "    try:\n",
    "        network_sc_date = first_heading.split('-')[1]\n",
    "        network_sc_date = network_sc_date.strip()\n",
    "        \n",
    "        print (network_sc_date)\n",
    "        \n",
    "        network_sc_date_as_date = datetime.datetime.strptime(network_sc_date, \"%B %d, %Y\").date()\n",
    "        \n",
    "        # print network_sc_date_as_date\n",
    "        \n",
    "        current_date = datetime.date.today()\n",
    "        \n",
    "        # print datetime.date.today()\n",
    "        \n",
    "        # print network_sc_date_as_date + datetime.timedelta(days = 33) == datetime.date.today()\n",
    "        \n",
    "        days_lag = abs(current_date - network_sc_date_as_date).days\n",
    "        \n",
    "        if days_lag == 0:\n",
    "            print (\"Dates Validated!\")\n",
    "            return True\n",
    "        else:\n",
    "            print (\"Scorecard is behind by: \", days_lag, \"days\")\n",
    "            return False\n",
    "        \n",
    "    except IndexError:\n",
    "        print (\"There was some problem parsing the date\")\n",
    "        return False\n",
    "    \n",
    "validate_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Fuction to get cell reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W17'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_cell_ref(increment):\n",
    "    global base_cell\n",
    "    base_cell\n",
    "    base_cell_int = int(base_cell[1:len(base_cell)])\n",
    "    base_cell_int += increment\n",
    "    new_cell_ref = base_cell[0] + str(base_cell_int)\n",
    "    return new_cell_ref\n",
    "\n",
    "get_cell_ref(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to read in cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(cell_ref):\n",
    "    data = network_sc_sheet[cell_ref].value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to traverse cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CE29'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_cols = []\n",
    "\n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append(chr(col))\n",
    "\n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('A' + chr(col))\n",
    "    \n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('B' + chr(col))\n",
    "    \n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('C' + chr(col))\n",
    "    \n",
    "def traverse_cells(cell, incx, incy, mode=0):\n",
    "    if mode == 0:\n",
    "        # w3\n",
    "        column_number = cell[0]\n",
    "        row_number = int(cell[1:len(cell)])\n",
    "    elif mode == 1:\n",
    "        #ab1\n",
    "        column_number = cell[0:2]\n",
    "        row_number = int(cell[2:len(cell)])\n",
    "        \n",
    "    index_of_col = list_of_cols.index(column_number)\n",
    "    index_of_col += incx\n",
    "    new_col = list_of_cols[index_of_col]\n",
    "    row_number += incy\n",
    "    new_cell_ref = new_col + str(row_number)\n",
    "    \n",
    "    return new_cell_ref\n",
    "    \n",
    "    \n",
    "    \n",
    "traverse_cells('BZ1', 5, 28, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to get a set of cells and return a pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>Δ01/01</td>\n",
       "      <td>Δ12/26</td>\n",
       "      <td>None</td>\n",
       "      <td>Δ2017</td>\n",
       "      <td>Δ2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oRPM</td>\n",
       "      <td>81.58</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1006</td>\n",
       "      <td>0.1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oPPC</td>\n",
       "      <td>93.4¢</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oCY</td>\n",
       "      <td>0.087</td>\n",
       "      <td>-0.0672</td>\n",
       "      <td>-0.1201</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>-0.2513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oMLIY</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.0183</td>\n",
       "      <td>-0.0679</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.0495</td>\n",
       "      <td>-0.0467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oVol</td>\n",
       "      <td>104mm</td>\n",
       "      <td>0.5926</td>\n",
       "      <td>0.2321</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.3034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oRev</td>\n",
       "      <td>$8.51mm</td>\n",
       "      <td>0.7284</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rev</td>\n",
       "      <td>$8.53mm</td>\n",
       "      <td>0.7278</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>None</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.4624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vol</td>\n",
       "      <td>117mm</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>0.2339</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>0.3307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RPM</td>\n",
       "      <td>72.95</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.0981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                    1       2       3     4       5       6\n",
       "0   None  2018-01-02 00:00:00  Δ01/01  Δ12/26  None   Δ2017   Δ2016\n",
       "1   oRPM                81.58  0.0853  -0.041  None  0.1006  0.1278\n",
       "2   oPPC                93.4¢  0.1635  0.0898  None  0.0412   0.076\n",
       "3    oCY                0.087 -0.0672 -0.1201  None  0.0571 -0.2513\n",
       "4  oMLIY                 0.65 -0.0183 -0.0679  None -0.0495 -0.0467\n",
       "5   oVol                104mm  0.5926  0.2321  None  -0.028  0.3034\n",
       "6   oRev              $8.51mm  0.7284  0.1816  None  0.0698    0.47\n",
       "7    Rev              $8.53mm  0.7278  0.1809  None    0.07  0.4624\n",
       "8    Vol                117mm  0.5902  0.2339  None -0.0032  0.3307\n",
       "9    RPM                72.95  0.0866  -0.043  None  0.0724  0.0981"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataframe(start_cell, end_cell):\n",
    "    data_rows = []\n",
    "    for row in network_sc_sheet[start_cell: end_cell]:\n",
    "        data_cols = []\n",
    "        for cell in row:\n",
    "            data_cols.append(cell.value)\n",
    "        data_rows.append(data_cols)\n",
    "    coverted_df = pd.DataFrame(data_rows) \n",
    "    return coverted_df\n",
    "\n",
    "get_dataframe('W20', 'AC29')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to extract numeric value from character string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_numeric(number_str):\n",
    "    list_of_chars = list(str(number_str))\n",
    "    \n",
    "    first_num_index = -1\n",
    "    \n",
    "    was_int = 0\n",
    "    \n",
    "    last_num_index = len(list_of_chars)-1\n",
    "    for x in range(0, len(list_of_chars)):\n",
    "        try:\n",
    "            char_as_num = int(list_of_chars[x])\n",
    "            was_int = 1\n",
    "        except ValueError:\n",
    "            was_int = 0\n",
    "        if was_int == 1:\n",
    "            break\n",
    "            \n",
    "    first_num_index = x\n",
    "    # print first_num_index\n",
    "    \n",
    "    was_char = 1\n",
    "    \n",
    "    for x in range(last_num_index, -1, -1):\n",
    "        try:\n",
    "            char_as_num = int(list_of_chars[x])\n",
    "            was_char = 0\n",
    "        except ValueError:\n",
    "            last_num_index -= 1\n",
    "            was_char = 1\n",
    "        if was_char == 0:\n",
    "            break\n",
    "    last_num_index = x\n",
    "    # print last_num_index\n",
    "    \n",
    "    return float(\"\".join(list_of_chars[first_num_index: last_num_index+1]))\n",
    "    \n",
    "convert_to_numeric('82.33')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base cell ref changed at this step -- Move to separate function\n",
    "\n",
    "#### Dates validated\n",
    "\n",
    "Check for Network Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to check missing and zero values in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "def check_missing_and_zero_values(column_list):\n",
    "    for value in column_list:\n",
    "            if isinstance(value, numbers.Number) is False:\n",
    "                if value is None:\n",
    "                    print (\"Missing values in First Table\")\n",
    "                    return False\n",
    "                else:\n",
    "                    try:\n",
    "                        length = len(value)\n",
    "                        if length < 2:\n",
    "                            print (\"Missing values in First Table\")\n",
    "                            return False\n",
    "                    except:\n",
    "                        print (\"Unknown stuff in First Table\")\n",
    "                        return False\n",
    "            else:\n",
    "                # number\n",
    "                number_as_float = float(value)\n",
    "                if float(value) == 0.0:\n",
    "                    print (\"Zero values in First Table\")\n",
    "                    return False\n",
    "                \n",
    "    return True\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to check 1st table data\n",
    "\n",
    "> Make it resuable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_first_table_data(first_table_df):\n",
    "    \n",
    "    # maybe date check should be done here?\n",
    "    print (first_table_df)\n",
    "    \n",
    "    # first_table_df[3][1] = 0\n",
    "    # first_table_df[2][3] = '*'\n",
    "    # first_table_df[2][4] = None\n",
    "    \n",
    "    if first_table_df.shape == (10, 7):\n",
    "        \n",
    "        # check for missing data\n",
    "        \n",
    "        first_table_df.drop([4], axis = 1, inplace = True)\n",
    "        # print first_table_df.columns\n",
    "        \n",
    "        for column_index in first_table_df.columns[1:]:\n",
    "            column_values = first_table_df[column_index][1:].tolist()\n",
    "            if check_missing_and_zero_values(column_values) is False:\n",
    "                return False\n",
    "    \n",
    "\n",
    "        \n",
    "        print (\"First Table data ok\")\n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print (\"Dimension of First Table does not match\")\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organic_metrics_validation(first_table_df):\n",
    "    \n",
    "    if first_table_df.shape == (10, 6):\n",
    "        \n",
    "        required_column = first_table_df[1][1:].tolist()\n",
    "        print (required_column)\n",
    "        \n",
    "        organic_metrics = required_column[:6]\n",
    "        non_organic_metrics = required_column[6:]\n",
    "        \n",
    "        oRev = organic_metrics[5]\n",
    "        oVol = organic_metrics[4]\n",
    "        Rev = non_organic_metrics[0]\n",
    "        Vol = non_organic_metrics[1]\n",
    "        \n",
    "        print (oRev, oVol, Rev, Vol)\n",
    "        \n",
    "        # test case: oRev = 10.00\n",
    "        \n",
    "        oRev = convert_to_numeric(oRev)\n",
    "        oVol = convert_to_numeric(oVol)\n",
    "        Rev = convert_to_numeric(Rev)\n",
    "        Vol = convert_to_numeric(Vol)\n",
    "        \n",
    "        print (oRev, oVol, Rev, Vol)\n",
    "        \n",
    "        if Rev < oRev or Vol < oVol:\n",
    "            print (\"Organic metrics greater than combined metrics which is not possible\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print (\"Dimension of First Table does not match\")\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Network Summary First table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates validated in First Table\n",
      "       0                    1       2       3     4       5       6\n",
      "0   None  2018-01-02 00:00:00  Δ01/01  Δ12/26  None   Δ2017   Δ2016\n",
      "1   oRPM                81.58  0.0853  -0.041  None  0.1006  0.1278\n",
      "2   oPPC                93.4¢  0.1635  0.0898  None  0.0412   0.076\n",
      "3    oCY                0.087 -0.0672 -0.1201  None  0.0571 -0.2513\n",
      "4  oMLIY                 0.65 -0.0183 -0.0679  None -0.0495 -0.0467\n",
      "5   oVol                104mm  0.5926  0.2321  None  -0.028  0.3034\n",
      "6   oRev              $8.51mm  0.7284  0.1816  None  0.0698    0.47\n",
      "7    Rev              $8.53mm  0.7278  0.1809  None    0.07  0.4624\n",
      "8    Vol                117mm  0.5902  0.2339  None -0.0032  0.3307\n",
      "9    RPM                72.95  0.0866  -0.043  None  0.0724  0.0981\n",
      "First Table data ok\n",
      "[81.58, '93.4¢', 0.087, 0.65, '104mm', '$8.51mm', '$8.53mm', '117mm', 72.95]\n",
      "$8.51mm 104mm $8.53mm 117mm\n",
      "8.51 104.0 8.53 117.0\n",
      "All ok in First Table!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_first_table():\n",
    "    cell_ref = get_cell_ref(3)\n",
    "    first_heading = str(read_data(cell_ref))\n",
    "    # print first_heading\n",
    "    \n",
    "    if first_heading.strip() != 'NETWORK SUMMARY':\n",
    "        print (\"Cannot find heading: NETWORK SUMMARY\")\n",
    "        return False\n",
    "    else:\n",
    "        # all ok until now\n",
    "        # try to find second heading\n",
    "        \n",
    "        second_heading = str(read_data(get_cell_ref(5)))\n",
    "        if second_heading.strip() != 'Bing O&O Core Browse':\n",
    "            print (\"Cannot find heading: Bing O&O Core Browse\")\n",
    "            return False\n",
    "        else:\n",
    "            # read in the range of cells\n",
    "            start_cell = get_cell_ref(6)\n",
    "            # print start_cell\n",
    "            \n",
    "            end_cell = traverse_cells(start_cell, widths[0]-1, heights[0]-1, 0)\n",
    "            # print end_cell\n",
    "            \n",
    "            network_summary_first_table_df = get_dataframe(start_cell, end_cell)\n",
    "            \n",
    "            \n",
    "            network_summary_first_table_date = network_summary_first_table_df.loc[0][1]\n",
    "            network_summary_first_table_date = datetime.datetime.date(network_summary_first_table_date)\n",
    "            \n",
    "            # print network_sc_date_as_date\n",
    "            \n",
    "            # print network_summary_first_table_date\n",
    "            \n",
    "            if (network_sc_date_as_date - network_summary_first_table_date).days == 1:\n",
    "                print (\"Dates validated in First Table\")\n",
    "                \n",
    "                # check table data\n",
    "                if check_first_table_data(network_summary_first_table_df) is False:\n",
    "                    return False\n",
    "                \n",
    "                if organic_metrics_validation(network_summary_first_table_df) is False:\n",
    "                    return False\n",
    "            \n",
    "            else:\n",
    "                print (\"Dates not validated in First Table\")\n",
    "                return False\n",
    "            \n",
    "            print (\"All ok in First Table!!\")\n",
    "            \n",
    "            return True\n",
    "    \n",
    "\n",
    "network_summary_first_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Nw Summary Second Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0                    1       2       3     4       5       6\n",
      "0    None  2018-01-02 00:00:00  Δ01/01  Δ12/26  None   Δ2017   Δ2016\n",
      "1   fpRPM                76.72  0.1166 -0.0125  None  0.0351 -0.0876\n",
      "2   fpPPC                70.7¢  0.1282  0.0158  None  0.0161 -0.0803\n",
      "3    fpCY                0.109 -0.0102 -0.0278  None  0.0186 -0.2914\n",
      "4  fpMLIY                 1.11  0.0528 -0.0001  None  0.1528  0.2887\n",
      "5   fpVol                  9mm  0.3286  0.1989  None -0.2323  -0.093\n",
      "6   fpRev              $0.65mm  0.4835  0.1839  None -0.2054 -0.1724\n",
      "7     Rev              $3.18mm  0.4307   0.159  None -0.0474  0.0816\n",
      "8     Vol                 55mm  0.2906  0.1873  None -0.1015  0.0917\n",
      "9     RPM                57.68  0.1085 -0.0238  None  0.0593 -0.0103\n",
      "Dates validated in Second Table\n",
      "        0                    1       2       3     4       5       6\n",
      "0    None  2018-01-02 00:00:00  Δ01/01  Δ12/26  None   Δ2017   Δ2016\n",
      "1   fpRPM                76.72  0.1166 -0.0125  None  0.0351 -0.0876\n",
      "2   fpPPC                70.7¢  0.1282  0.0158  None  0.0161 -0.0803\n",
      "3    fpCY                0.109 -0.0102 -0.0278  None  0.0186 -0.2914\n",
      "4  fpMLIY                 1.11  0.0528 -0.0001  None  0.1528  0.2887\n",
      "5   fpVol                  9mm  0.3286  0.1989  None -0.2323  -0.093\n",
      "6   fpRev              $0.65mm  0.4835  0.1839  None -0.2054 -0.1724\n",
      "7     Rev              $3.18mm  0.4307   0.159  None -0.0474  0.0816\n",
      "8     Vol                 55mm  0.2906  0.1873  None -0.1015  0.0917\n",
      "9     RPM                57.68  0.1085 -0.0238  None  0.0593 -0.0103\n",
      "First Table data ok\n",
      "All ok in Second Table!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_second_table():\n",
    "    \n",
    "    # read in the range of cells\n",
    "    start_cell = traverse_cells(base_cell, x_offsets[1], y_offsets[1], 0)\n",
    "    \n",
    "    end_cell = traverse_cells(base_cell, x_offsets[1] + widths[1] - 1, y_offsets[1] + heights[1] - 1, 0)\n",
    "\n",
    "    network_summary_second_table_df = get_dataframe(start_cell, end_cell)\n",
    "\n",
    "    \n",
    "    print (network_summary_second_table_df)\n",
    "\n",
    "    network_summary_second_table_date = network_summary_second_table_df.loc[0][1]\n",
    "    network_summary_second_table_date = datetime.datetime.date(network_summary_second_table_date)\n",
    "\n",
    "    # print network_sc_date_as_date\n",
    "\n",
    "    # print network_summary_first_table_date\n",
    "\n",
    "    if (network_sc_date_as_date - network_summary_second_table_date).days == 1:\n",
    "        print (\"Dates validated in Second Table\")\n",
    "\n",
    "        # check table data\n",
    "        if check_first_table_data(network_summary_second_table_df) is False:\n",
    "            return False\n",
    "\n",
    "    else:\n",
    "        print (\"Dates not validated in Second Table\")\n",
    "        return False\n",
    "\n",
    "    print (\"All ok in Second Table!!\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "network_summary_second_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check NW Summary Third Table (Smart Pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
