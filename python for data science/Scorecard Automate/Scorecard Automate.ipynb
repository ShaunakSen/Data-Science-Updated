{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scorecard Automation\n",
    "\n",
    "#### General Outline\n",
    "\n",
    "- First find **offset**\n",
    "- Check date\n",
    "- Read tables one by one\n",
    "- check for missing tables\n",
    "- Check data in each tabel\n",
    "- Check for missing data\n",
    "- Check if charts exist\n",
    "- Validate data with rnramd\n",
    "\n",
    "___\n",
    "\n",
    "**Write function to determine which sheet contains which data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of offsets\n",
    "\n",
    "> Network Summary Heading : 3\n",
    "\n",
    "> Bing O&O Core Browse:\n",
    "\n",
    "---\n",
    "\n",
    "**Make these global vars so that they can be changed anytime**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_offsets = [0, 21, 29, 1, 19, 27, 35, -1, -1, -1, 1]\n",
    "\n",
    "y_offsets = [6, 6, 6, 18, 18, 18, 18, -1, -1, -1, 61]\n",
    "widths = [7, 7, 7, 5, 5, 5, 2, -1, -1, -1, 12]\n",
    "\n",
    "heights = [10, 10, 10, 8, 8, 8, 8, -1, -1, -1, 12]\n",
    "\n",
    "max_allowable_perc_adv = 1000\n",
    "\n",
    "segment_names = ['Strategic/Tier 1', 'Mid Market/Tier 2', 'Scale/Tier 3', 'Channel Partner']\n",
    "\n",
    "if not(len(x_offsets) == len(y_offsets) == len(widths) == len(heights)):\n",
    "    print (\"Table metadata not consistent!\")\n",
    "    raise InterruptedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Development mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print (platform.system())\n",
    "\n",
    "dev_mode = platform.system()\n",
    "\n",
    "if dev_mode == \"Linux\":\n",
    "    root_path = \"/media/shaunak/New Volume/my_projects/data science updated/python for data science/Scorecard Automate/data/\"\n",
    "elif dev_mode == \"Windows\":\n",
    "    root_path = \"D:/data_science-master/python for data science/Scorecard Automate/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             1       2       3     4       5       6\n",
      "0                                                   \n",
      "oRPM     72.81 -0.0228 -0.0254  None  0.1085  0.1562\n",
      "oPPC     92.5Â¢ -0.0106 -0.0194  None  0.0233  0.1022\n",
      "oCY      0.079 -0.0123 -0.0061  None  0.0833  0.0490\n",
      "oMLIY     0.56 -0.0251 -0.0093  None -0.0892 -0.1155\n",
      "oVol     117mm -0.0219  0.0063  None  0.0200  0.0417\n",
      "oRev   $8.52mm -0.0442 -0.0193  None  0.1306  0.2045\n",
      "Rev    $8.55mm -0.0442 -0.0190  None  0.1327  0.1995\n",
      "Vol      129mm -0.0437 -0.0092  None  0.0632  0.0795\n",
      "RPM      66.52 -0.0005 -0.0099  None  0.0651  0.1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor row in sheet_nw_sc.iter_rows(min_row=21,min_col=23, max_col=30, max_row=25):\\n    for cell in row:\\n        print cell.value\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import quandl\n",
    "import datetime\n",
    "\n",
    "wb = openpyxl.load_workbook(filename=root_path + 'data.xlsx', \n",
    "                   read_only=True)\n",
    "sheet_nw_sc = wb['Sheet4']\n",
    "\n",
    "data_rows = []\n",
    "for row in sheet_nw_sc['W10':'AC18']:\n",
    "    data_cols = []\n",
    "    for cell in row:\n",
    "        data_cols.append(cell.value)\n",
    "    data_rows.append(data_cols)\n",
    "\n",
    "    \n",
    "nw_sc_df = pd.DataFrame(data_rows)\n",
    "\n",
    "nw_sc_df.set_index(0, inplace=True)\n",
    "\n",
    "print (nw_sc_df)\n",
    "\n",
    "\"\"\"\n",
    "for row in sheet_nw_sc.iter_rows(min_row=21,min_col=23, max_col=30, max_row=25):\n",
    "    for cell in row:\n",
    "        print cell.value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the file + determining offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "offset to be changed\n",
      "Offset changed\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "\n",
    "base_cell = 'W3'\n",
    "\n",
    "network_sc_date_as_date = \"\"\n",
    "\n",
    "workbook = openpyxl.load_workbook(filename = root_path + 'data3.xlsx', \n",
    "                   read_only=True)\n",
    "\n",
    "network_sc_sheet = workbook['Sheet4']\n",
    "\n",
    "first_heading = str(network_sc_sheet['W3'].value)\n",
    "\n",
    "print (first_heading.strip('-'))\n",
    "\n",
    "\n",
    "if first_heading is None or first_heading.split('-')[0].strip() != 'SEARCH BG SCORECARD':\n",
    "    # print first_heading.split('-')[0].strip()\n",
    "    print (\"offset to be changed\")\n",
    "    \n",
    "    first_heading = str(network_sc_sheet['W14'].value)\n",
    "    \n",
    "    if first_heading.split('-')[0].strip() == 'SEARCH BG SCORECARD':\n",
    "        offset = 11\n",
    "        print (\"Offset changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offset changed at this step -- Move to separate function\n",
    "\n",
    "#### Validating the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W14\n",
      "January 3, 2018\n",
      "Scorecard is behind by:  45 days\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_date():\n",
    "    global offset\n",
    "    global base_cell\n",
    "    global network_sc_sheet\n",
    "    global network_sc_date_as_date\n",
    "    # base cell = W3\n",
    "    base_cell_num = int(base_cell[1:len(base_cell)])\n",
    "    base_cell_num += offset\n",
    "    \n",
    "    cell_ref = base_cell[0] + str(base_cell_num)\n",
    "    \n",
    "    print (cell_ref)\n",
    "    \n",
    "    # Modifying the base cell\n",
    "    \n",
    "    base_cell = cell_ref\n",
    "    \n",
    "    first_heading = network_sc_sheet[cell_ref].value\n",
    "    \n",
    "    try:\n",
    "        network_sc_date = first_heading.split('-')[1]\n",
    "        network_sc_date = network_sc_date.strip()\n",
    "        \n",
    "        print (network_sc_date)\n",
    "        \n",
    "        network_sc_date_as_date = datetime.datetime.strptime(network_sc_date, \"%B %d, %Y\").date()\n",
    "        \n",
    "        # print network_sc_date_as_date\n",
    "        \n",
    "        current_date = datetime.date.today()\n",
    "        \n",
    "        # print datetime.date.today()\n",
    "        \n",
    "        # print network_sc_date_as_date + datetime.timedelta(days = 33) == datetime.date.today()\n",
    "        \n",
    "        days_lag = abs(current_date - network_sc_date_as_date).days\n",
    "        \n",
    "        if days_lag == 0:\n",
    "            print (\"Dates Validated!\")\n",
    "            return True\n",
    "        else:\n",
    "            print (\"Scorecard is behind by: \", days_lag, \"days\")\n",
    "            return False\n",
    "        \n",
    "    except IndexError:\n",
    "        print (\"There was some problem parsing the date\")\n",
    "        return False\n",
    "    \n",
    "validate_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Fuction to get cell reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W17'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_cell_ref(increment):\n",
    "    global base_cell\n",
    "    base_cell\n",
    "    base_cell_int = int(base_cell[1:len(base_cell)])\n",
    "    base_cell_int += increment\n",
    "    new_cell_ref = base_cell[0] + str(base_cell_int)\n",
    "    return new_cell_ref\n",
    "\n",
    "get_cell_ref(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to read in cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(cell_ref):\n",
    "    data = network_sc_sheet[cell_ref].value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to traverse cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CE29'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_cols = []\n",
    "\n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append(chr(col))\n",
    "\n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('A' + chr(col))\n",
    "    \n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('B' + chr(col))\n",
    "    \n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('C' + chr(col))\n",
    "    \n",
    "def traverse_cells(cell, incx, incy, mode=0):\n",
    "    if mode == 0:\n",
    "        # w3\n",
    "        column_number = cell[0]\n",
    "        row_number = int(cell[1:len(cell)])\n",
    "    elif mode == 1:\n",
    "        #ab1\n",
    "        column_number = cell[0:2]\n",
    "        row_number = int(cell[2:len(cell)])\n",
    "        \n",
    "    index_of_col = list_of_cols.index(column_number)\n",
    "    index_of_col += incx\n",
    "    new_col = list_of_cols[index_of_col]\n",
    "    row_number += incy\n",
    "    new_cell_ref = new_col + str(row_number)\n",
    "    \n",
    "    return new_cell_ref\n",
    "    \n",
    "    \n",
    "    \n",
    "traverse_cells('BZ1', 5, 28, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to get a set of cells and return a pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>Î01/01</td>\n",
       "      <td>Î12/26</td>\n",
       "      <td>None</td>\n",
       "      <td>Î2017</td>\n",
       "      <td>Î2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RPM</td>\n",
       "      <td>30.68</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>-0.0505</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.6015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PPC</td>\n",
       "      <td>53.6Â¢</td>\n",
       "      <td>-0.0123</td>\n",
       "      <td>-0.0816</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.1081</td>\n",
       "      <td>0.1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CY</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2541</td>\n",
       "      <td>0.0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IY</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.2203</td>\n",
       "      <td>-0.3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vol</td>\n",
       "      <td>30mm</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.1021</td>\n",
       "      <td>0.0199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rev</td>\n",
       "      <td>$0.91mm</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cCPAi</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>None</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rCPAi</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>None</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SP Disc</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.02pp</td>\n",
       "      <td>0.08pp</td>\n",
       "      <td>None</td>\n",
       "      <td>-11.69pp</td>\n",
       "      <td>-14.26pp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                    1       2       3     4         5         6\n",
       "0     None  2018-01-02 00:00:00  Î01/01  Î12/26  None     Î2017     Î2016\n",
       "1      RPM                30.68  0.0107 -0.0505  None    0.1186    0.6015\n",
       "2      PPC                53.6Â¢ -0.0123 -0.0816  None   -0.1081    0.1209\n",
       "3       CY                0.057  0.0233  0.0339  None    0.2541    0.0206\n",
       "4       IY                 3.41  0.0481  0.0269  None   -0.2203   -0.3808\n",
       "5      Vol                 30mm  0.2145  0.1917  None   -0.1021    0.0199\n",
       "6      Rev              $0.91mm  0.2275  0.1315  None    0.0044    0.6335\n",
       "7    cCPAi                    *       *       *  None         *         *\n",
       "8    rCPAi                    *       *       *  None         *         *\n",
       "9  SP Disc               0.0069  0.02pp  0.08pp  None  -11.69pp  -14.26pp"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataframe(start_cell, end_cell):\n",
    "    data_rows = []\n",
    "    for row in network_sc_sheet[start_cell: end_cell]:\n",
    "        data_cols = []\n",
    "        for cell in row:\n",
    "            data_cols.append(cell.value)\n",
    "        data_rows.append(data_cols)\n",
    "    coverted_df = pd.DataFrame(data_rows) \n",
    "    return coverted_df\n",
    "\n",
    "get_dataframe('AZ20', 'BF29')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to extract numeric value from character string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String in func: 93.4Â¢\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import types\n",
    "\n",
    "def convert_to_numeric(number_str):\n",
    "    print (\"String in func:\", number_str)\n",
    "    \n",
    "    \n",
    "    if dev_mode == 'linux':\n",
    "        if type(number_str) == type(b'mini'):\n",
    "            number_str = number_str.decode()\n",
    "    list_of_chars = list(str(number_str))\n",
    "    \n",
    "    first_num_index = -1\n",
    "    \n",
    "    was_int = 0\n",
    "    \n",
    "    last_num_index = len(list_of_chars)-1\n",
    "    for x in range(0, len(list_of_chars)):\n",
    "        try:\n",
    "            char_as_num = int(list_of_chars[x])\n",
    "            was_int = 1\n",
    "        except ValueError:\n",
    "            was_int = 0\n",
    "        if was_int == 1:\n",
    "            break\n",
    "            \n",
    "    first_num_index = x\n",
    "    # print first_num_index\n",
    "    \n",
    "    was_char = 1\n",
    "    \n",
    "    for x in range(last_num_index, -1, -1):\n",
    "        try:\n",
    "            char_as_num = int(list_of_chars[x])\n",
    "            was_char = 0\n",
    "        except ValueError:\n",
    "            last_num_index -= 1\n",
    "            was_char = 1\n",
    "        if was_char == 0:\n",
    "            break\n",
    "    last_num_index = x\n",
    "    # print last_num_index\n",
    "    \n",
    "    if (last_num_index < first_num_index):\n",
    "        return False\n",
    "    else:\n",
    "        return float(\"\".join(list_of_chars[first_num_index: last_num_index+1]))\n",
    "    \n",
    "convert_to_numeric('93.4Â¢')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base cell ref changed at this step -- Move to separate function\n",
    "\n",
    "#### Dates validated\n",
    "\n",
    "Check for Network Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to check missing and zero values in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to check 1st table data\n",
    "\n",
    "> Make it resuable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_smart_pricing_data(first_table_df):\n",
    "    \n",
    "    # maybe date check should be done here\n",
    "    \n",
    "    # first_table_df[3][1] = 0\n",
    "    # first_table_df[2][3] = '*'\n",
    "    # first_table_df[2][4] = None\n",
    "    \n",
    "    # check for missing data\n",
    "\n",
    "    # print first_table_df.columns\n",
    "\n",
    "    for column_index in first_table_df.columns[1:]:\n",
    "        column_values = first_table_df[column_index][1:].tolist()\n",
    "        if check_missing_and_zero_values(column_values) is False:\n",
    "            print (\"Smart Pricing Data Missing\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    print (\"Smart Pricing data ok\")\n",
    "    return True\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** When we convert to utf-8 in python 3 it will get converted as a byte string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "def check_missing_and_zero_values(column_list):\n",
    "    for value in column_list:\n",
    "        print (value)\n",
    "        if isinstance(value, numbers.Number) is False:\n",
    "            if value is None:\n",
    "                print (\"Missing values in First Table\")\n",
    "                return False\n",
    "            else:\n",
    "\n",
    "                # not a number \n",
    "                # maybe: '$#%$%'\n",
    "                try:\n",
    "                    length = len(value)\n",
    "                    if length < 2:\n",
    "                        print (\"Missing values in First Table\")\n",
    "                        return False\n",
    "                    else:\n",
    "                        # problem here: what if u cant encode??\n",
    "                        if dev_mode == 'Linux':\n",
    "                            value = value.encode('utf-8')\n",
    "                        else:\n",
    "                            value = value.encode('utf-8')\n",
    "                        if convert_to_numeric(value) is False:\n",
    "                            print (\"Missing values in First Table\")\n",
    "                            return False\n",
    "\n",
    "                except:\n",
    "                    print (\"Unknown stuff in First Table\")\n",
    "                    return False\n",
    "        else:\n",
    "            # number\n",
    "            number_as_float = float(value)\n",
    "            if float(value) == 0.0:\n",
    "                print (\"Zero values in First Table\")\n",
    "                return False\n",
    "                \n",
    "    return True\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_table_data(table_df, table_number):\n",
    "    \n",
    "    # maybe date check should be done here\n",
    "    \n",
    "    # first_table_df[3][1] = 0\n",
    "    # first_table_df[2][3] = '*'\n",
    "    # first_table_df[2][4] = None\n",
    "    \n",
    "    height_of_table = heights[table_number - 1]\n",
    "    width_of_table = widths[table_number - 1]\n",
    "    \n",
    "    if table_df.shape == (height_of_table, width_of_table):\n",
    "        \n",
    "        # check for missing data\n",
    "        \n",
    "        if table_number!= 7:\n",
    "            table_df.drop([4], axis = 1, inplace = True)\n",
    "            # print first_table_df.columns\n",
    "        \n",
    "        for column_index in table_df.columns[1:]:\n",
    "            column_values = table_df[column_index][1:].tolist()\n",
    "            if check_missing_and_zero_values(column_values) is False:\n",
    "                return False\n",
    "    \n",
    "\n",
    "        \n",
    "        print (\"Data ok for table number:\", table_number)\n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print (\"Dimension of does not match for table number:\", table_number)\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def organic_metrics_validation(first_table_df):\n",
    "    \n",
    "    if first_table_df.shape == (10, 6):\n",
    "        \n",
    "        required_column = first_table_df[1][1:].tolist()\n",
    "        print (required_column)\n",
    "        \n",
    "        organic_metrics = required_column[:6]\n",
    "        non_organic_metrics = required_column[6:]\n",
    "        \n",
    "        oRev = organic_metrics[5]\n",
    "        oVol = organic_metrics[4]\n",
    "        Rev = non_organic_metrics[0]\n",
    "        Vol = non_organic_metrics[1]\n",
    "        \n",
    "        print (oRev, oVol, Rev, Vol)\n",
    "        \n",
    "        # test case: oRev = 10.00\n",
    "        \n",
    "        oRev = convert_to_numeric(oRev)\n",
    "        oVol = convert_to_numeric(oVol)\n",
    "        Rev = convert_to_numeric(Rev)\n",
    "        Vol = convert_to_numeric(Vol)\n",
    "        \n",
    "        print (oRev, oVol, Rev, Vol)\n",
    "        \n",
    "        if Rev < oRev or Vol < oVol:\n",
    "            print (\"Organic metrics greater than combined metrics which is not possible\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print (\"Dimension of First Table does not match\")\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Network Summary First table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates validated in First Table\n",
      "81.58\n",
      "93.4Â¢\n",
      "String in func: b'93.4\\xc2\\xa2'\n",
      "Unknown stuff in First Table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_first_table():\n",
    "    cell_ref = get_cell_ref(3)\n",
    "    first_heading = str(read_data(cell_ref))\n",
    "    # print first_heading\n",
    "    \n",
    "    if first_heading.strip() != 'NETWORK SUMMARY':\n",
    "        print (\"Cannot find heading: NETWORK SUMMARY\")\n",
    "        return False\n",
    "    else:\n",
    "        # all ok until now\n",
    "        # try to find second heading\n",
    "        \n",
    "        second_heading = str(read_data(get_cell_ref(5)))\n",
    "        if second_heading.strip() != 'Bing O&O Core Browse':\n",
    "            print (\"Cannot find heading: Bing O&O Core Browse\")\n",
    "            return False\n",
    "        else:\n",
    "            # read in the range of cells\n",
    "            start_cell = get_cell_ref(6)\n",
    "            # print start_cell\n",
    "            \n",
    "            end_cell = traverse_cells(start_cell, widths[0]-1, heights[0]-1, 0)\n",
    "            # print end_cell\n",
    "            \n",
    "            network_summary_first_table_df = get_dataframe(start_cell, end_cell)\n",
    "            \n",
    "            \n",
    "            network_summary_first_table_date = network_summary_first_table_df.loc[0][1]\n",
    "            network_summary_first_table_date = datetime.datetime.date(network_summary_first_table_date)\n",
    "            \n",
    "            # print network_sc_date_as_date\n",
    "            \n",
    "            # print network_summary_first_table_date\n",
    "            \n",
    "            if (network_sc_date_as_date - network_summary_first_table_date).days == 1:\n",
    "                print (\"Dates validated in First Table\")\n",
    "                \n",
    "                # check table data\n",
    "                if check_table_data(network_summary_first_table_df, 1) is False:\n",
    "                    return False\n",
    "                \n",
    "                if organic_metrics_validation(network_summary_first_table_df) is False:\n",
    "                    return False\n",
    "            \n",
    "            else:\n",
    "                print (\"Dates not validated in First Table\")\n",
    "                return False\n",
    "            \n",
    "            print (\"All ok in First Table!!\")\n",
    "            \n",
    "            return True\n",
    "    \n",
    "\n",
    "network_summary_first_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Nw Summary Second Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates validated in Second Table\n",
      "76.72\n",
      "70.7Â¢\n",
      "String in func: b'70.7\\xc2\\xa2'\n",
      "Unknown stuff in First Table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_second_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[1], y_offsets[1]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    if second_heading.strip() != 'Yahoo O&O':\n",
    "        print (\"Cannot find heading: Yahoo O&O\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[1], y_offsets[1], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[1] + widths[1] - 1, y_offsets[1] + heights[1] - 1, 0)\n",
    "\n",
    "        network_summary_second_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_second_table_date = network_summary_second_table_df.loc[0][1]\n",
    "        network_summary_second_table_date = datetime.datetime.date(network_summary_second_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_second_table_date).days == 1:\n",
    "            print (\"Dates validated in Second Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_second_table_df, 2) is False:\n",
    "                return False\n",
    "\n",
    "        else:\n",
    "            print (\"Dates not validated in Second Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Second Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_second_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check NW Summary Third Table (Smart Pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZ20 BF29\n",
      "Dates validated in Third Table\n",
      "30.68\n",
      "53.6Â¢\n",
      "String in func: b'53.6\\xc2\\xa2'\n",
      "Unknown stuff in First Table\n",
      "30.68\n",
      "53.6Â¢\n",
      "String in func: b'53.6\\xc2\\xa2'\n",
      "Unknown stuff in First Table\n",
      "Smart Pricing Data Missing\n",
      "Samrt Pricing Data not available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_third_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[2], y_offsets[2]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    if second_heading.strip() != 'Yahoo Syndication':\n",
    "        print (\"Cannot find heading: Yahoo Syndication\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[2], y_offsets[2], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[2] + widths[2] - 1, y_offsets[2] + heights[2] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_third_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_third_table_date = network_summary_third_table_df.loc[0][1]\n",
    "        network_summary_third_table_date = datetime.datetime.date(network_summary_third_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_third_table_date).days == 1:\n",
    "            print (\"Dates validated in Third Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_third_table_df, 3) is False:\n",
    "                if check_smart_pricing_data(network_summary_third_table_df) is False:\n",
    "                    print (\"Samrt Pricing Data not available\")\n",
    "                    return False\n",
    "                else:\n",
    "                    print (\"Missing values in Third Table\")\n",
    "                    return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Third Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Third Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_third_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOL O&O Guaranty (PC Only)\n",
      "X32 AB39\n",
      "Dates validated in Fourth Table\n",
      "110.15\n",
      "63.3Â¢\n",
      "String in func: b'63.3\\xc2\\xa2'\n",
      "Unknown stuff in First Table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_fourth_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[3], y_offsets[3]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'AOL O&O Guaranty (PC Only)':\n",
    "        print (\"Cannot find heading: AOL O&O Guaranty (PC Only)\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[3], y_offsets[3], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[3] + widths[3] - 1, y_offsets[3] + heights[3] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_fourth_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_fourth_table_date = network_summary_fourth_table_df.loc[0][1]\n",
    "        network_summary_fourth_table_date = datetime.datetime.date(network_summary_fourth_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_fourth_table_date).days == 1:\n",
    "            print (\"Dates validated in Fourth Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_fourth_table_df,4) is False:\n",
    "                return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Fourth Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Fourth Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_fourth_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOL O&O\n",
      "AP32 AT39\n",
      "Dates validated in Fifth Table\n",
      "93.65\n",
      "63.5Â¢\n",
      "String in func: b'63.5\\xc2\\xa2'\n",
      "Unknown stuff in First Table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_fifth_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[4], y_offsets[4]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'AOL O&O':\n",
    "        print (\"Cannot find heading: AOL O&O\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[4], y_offsets[4], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[4] + widths[4] - 1, y_offsets[4] + heights[4] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_fifth_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_fifth_table_date = network_summary_fifth_table_df.loc[0][1]\n",
    "        network_summary_fifth_table_date = datetime.datetime.date(network_summary_fifth_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_fifth_table_date).days == 1:\n",
    "            print (\"Dates validated in Fifth Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_fifth_table_df, 5) is False:\n",
    "                return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Fifth Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Fifth Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_fifth_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOL Syndication\n",
      "AX32 BB39\n",
      "Dates validated in Fifth Table\n",
      "48.14\n",
      "26.4Â¢\n",
      "String in func: b'26.4\\xc2\\xa2'\n",
      "Unknown stuff in First Table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_sixth_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[5], y_offsets[5]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'AOL Syndication':\n",
    "        print (\"Cannot find heading: AOL Syndication\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[5], y_offsets[5], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[5] + widths[5] - 1, y_offsets[5] + heights[5] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_sixth_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_sixth_table_date = network_summary_sixth_table_df.loc[0][1]\n",
    "        network_summary_sixth_table_date = datetime.datetime.date(network_summary_sixth_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_sixth_table_date).days == 1:\n",
    "            print (\"Dates validated in Fifth Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_sixth_table_df, 6) is False:\n",
    "                return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Fifth Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Fifth Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_sixth_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOL (O&O and Syndication)\n",
      "BF32 BG39\n",
      "Dates validated in Fifth Table\n",
      "80.1\n",
      "50.73Â¢\n",
      "String in func: b'50.73\\xc2\\xa2'\n",
      "Unknown stuff in First Table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_seventh_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[6], y_offsets[6]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'AOL (O&O and Syndication)':\n",
    "        print (\"Cannot find heading: AOL Syndication\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[6], y_offsets[6], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[6] + widths[6] - 1, y_offsets[6] + heights[6] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_seventh_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_seventh_table_date = network_summary_seventh_table_df.loc[0][1]\n",
    "        network_summary_seventh_table_date = datetime.datetime.date(network_summary_seventh_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_seventh_table_date).days == 1:\n",
    "            print (\"Dates validated in Fifth Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_seventh_table_df, 7) is False:\n",
    "                return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Seventh Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Seventh Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_seventh_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Network Summary In-place validation done\n",
    "\n",
    "#### Advertiser Metrics Validation\n",
    "\n",
    "- Check if each segment is there\n",
    "- No missing values\n",
    "- No 0 values in performing 1st 2 segments\n",
    "- No abrubt % changes\n",
    "\n",
    "Note: special chars might come up in Adv names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Function: Custom Error Generation Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_error_message(table_number, column_number, adv_number):\n",
    "    \n",
    "    segment_number = int(((column_number+3)/3)-1)\n",
    "    \n",
    "    \n",
    "    if (column_number+3)%3 == 0:\n",
    "         \n",
    "        print (\"Check Segement: \", segment_names[segment_number], \"Check Column: Customer, Advertiser Number:\", adv_number)\n",
    "    elif (column_number+3)%3 == 1:\n",
    "        print (\"Check Segement: \", segment_names[segment_number], \"Check Column: Spend, Advertiser Number:\", adv_number)\n",
    "    else:\n",
    "        print (\"Check Segement: \", segment_names[segment_number], \"Check Column: Spend WoW, Advertiser Number:\", adv_number)\n",
    "        \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "def check_missing_values(column_list, column_number, table_number):\n",
    "    \n",
    "    # Modify these functions to help know where EXACTLY error occured\n",
    "    \n",
    "    # Missing value in Customer:Adv no:5\n",
    "    \n",
    "    \n",
    "    print (\"Col list in func:\", column_list)\n",
    "    \n",
    "    \n",
    "    adv_number = 0\n",
    "    for value in column_list:\n",
    "        print (value)\n",
    "        print (column_number, adv_number)\n",
    "        if isinstance(value, numbers.Number) is False:\n",
    "            if value is None:\n",
    "                print (\"Missing Value in Table Number:\", table_number)\n",
    "                generate_error_message(table_number, column_number, adv_number)\n",
    "                return False\n",
    "            else:\n",
    "        \n",
    "                try:\n",
    "                    length = len(value)\n",
    "                    if length < 2:\n",
    "                        print (\"Missing Value in Table Number:\", table_number)\n",
    "                        generate_error_message(table_number, column_number, adv_number)\n",
    "                        return False\n",
    "                except:\n",
    "                    print (\"Unknown Stuff in Table Number:\", table_number)\n",
    "                    return False\n",
    "        adv_number += 1\n",
    "                \n",
    "    return True\n",
    "\n",
    "\n",
    "import numbers\n",
    "\n",
    "def check_zero_values(column_list):\n",
    "    for value in column_list:\n",
    "        print (value)\n",
    "        if isinstance(value, numbers.Number) is False:\n",
    "            \n",
    "            # not a number: not possible\n",
    "            print (\"Advertiser Metric Spend should be numerical\")\n",
    "            return False\n",
    "            \n",
    "        else:\n",
    "            # number\n",
    "            number_as_float = float(value)\n",
    "            if number_as_float == 0.0:\n",
    "                print (\"Zero value in First 2 Segemnts!\")\n",
    "                return False\n",
    "                \n",
    "    return True\n",
    "\n",
    "def check_abrupt_values(column_list):\n",
    "    for value in column_list:\n",
    "        print (value)\n",
    "        if isinstance(value, numbers.Number) is False:\n",
    "            \n",
    "            # not a number: not possible\n",
    "            print (\"Advertiser Metric Spend WoW should be numerical\")\n",
    "            return False\n",
    "            \n",
    "        else:\n",
    "            # number\n",
    "            number_as_float = float(value)\n",
    "            if number_as_float*100 > 200:\n",
    "                print (\"Spend WoW % > Allowable %:\", max_allowable_perc_adv)\n",
    "                \n",
    "                # dont return False , just alert user\n",
    "                return False\n",
    "                \n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def validate_advertiser_metrics(adv_df, table_number):\n",
    "    \n",
    "    # check if each segement is there of not\n",
    "    \n",
    "    # test case: adv_df[0][0] = \"\"\n",
    "    try:\n",
    "        \n",
    "        # get segment names\n",
    "        \n",
    "        first_segment = adv_df[0][0].strip()\n",
    "        second_segment = adv_df[3][0].strip()\n",
    "        third_segement = adv_df[6][0].strip()\n",
    "        fourth_segment = adv_df[9][0].strip()\n",
    "        \n",
    "        \n",
    "        adv_df[3][5] = \"*\"\n",
    "        \n",
    "        print (first_segment, second_segment, third_segement, fourth_segment)\n",
    "\n",
    "        # validate segment names\n",
    "        \n",
    "        if first_segment != segment_names[0] or second_segment != segment_names[1] or third_segement != segment_names[2] or fourth_segment != segment_names[3]:\n",
    "            print (\"Segment Names not matching in Advertiser Metrics Table Number:\", table_number)\n",
    "            return False\n",
    "    except:\n",
    "        print(\"Unknown stuff in Advertiser Metrics Table Number:\", table_number)\n",
    "        return False\n",
    "    \n",
    "    # check for misisng values for entire df\n",
    "    \n",
    "    for column_index in adv_df.columns:\n",
    "            column_values = adv_df[column_index][1:].tolist()\n",
    "            if check_missing_values(column_values, column_index, table_number) is False:\n",
    "                return False\n",
    "            \n",
    "    # check for 0 values in first 2 segments\n",
    "    \n",
    "        # check for 0 value in spend\n",
    "        # check for abrupt % change in Spend WoW\n",
    "        \n",
    "        \n",
    "    # 1, 4, \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for column_index in range(1, 5, 3):\n",
    "        column_values = adv_df[column_index][2:].tolist()\n",
    "        if check_zero_values(column_values) is False:\n",
    "            return False\n",
    "        \n",
    "    # 2, 5, 8, 11\n",
    "        \n",
    "    for column_index in range(2, 12, 3):\n",
    "        column_values = adv_df[column_index][2:].tolist()\n",
    "        if check_abrupt_values(column_values) is False:\n",
    "            return False\n",
    "        \n",
    "    \"\"\"\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Spend Performing Customers\n",
      "X75 AI86\n",
      "Strategic/Tier 1 Mid Market/Tier 2 Scale/Tier 3 Channel Partner\n",
      "Col list in func: ['Customer', 'Amazon Service LLC', 'Pfizer Inc Ny', 'Booking.com B.V.', 'Ford Motor Media', 'United Healthcare', 'Expedia POSu', 'JCP Media L.P.', 'HomeAdvisor, Inc.', 'AT & T', 'Petra Digital Inc']\n",
      "Customer\n",
      "0 0\n",
      "Amazon Service LLC\n",
      "0 1\n",
      "Pfizer Inc Ny\n",
      "0 2\n",
      "Booking.com B.V.\n",
      "0 3\n",
      "Ford Motor Media\n",
      "0 4\n",
      "United Healthcare\n",
      "0 5\n",
      "Expedia POSu\n",
      "0 6\n",
      "JCP Media L.P.\n",
      "0 7\n",
      "HomeAdvisor, Inc.\n",
      "0 8\n",
      "AT & T\n",
      "0 9\n",
      "Petra Digital Inc\n",
      "0 10\n",
      "Col list in func: ['Spend', 205455, 128729, 128231, 113749, 94048, 87029, 86409, 85232, 83455, 81678]\n",
      "Spend\n",
      "1 0\n",
      "205455\n",
      "1 1\n",
      "128729\n",
      "1 2\n",
      "128231\n",
      "1 3\n",
      "113749\n",
      "1 4\n",
      "94048\n",
      "1 5\n",
      "87029\n",
      "1 6\n",
      "86409\n",
      "1 7\n",
      "85232\n",
      "1 8\n",
      "83455\n",
      "1 9\n",
      "81678\n",
      "1 10\n",
      "Col list in func: ['Spend WoW', 0.476, 0.0929, 0.24, -0.0128, 0.8907, 0.2695, 0.2051, 0.3823, 0.0659, -0.0246]\n",
      "Spend WoW\n",
      "2 0\n",
      "0.476\n",
      "2 1\n",
      "0.0929\n",
      "2 2\n",
      "0.24\n",
      "2 3\n",
      "-0.0128\n",
      "2 4\n",
      "0.8907\n",
      "2 5\n",
      "0.2695\n",
      "2 6\n",
      "0.2051\n",
      "2 7\n",
      "0.3823\n",
      "2 8\n",
      "0.0659\n",
      "2 9\n",
      "-0.0246\n",
      "2 10\n",
      "Col list in func: ['Customer', 'Houzz Inc.', 'Selectcomfort.com', 'Natural Intelligence, Inc.', '*', 'GoodRx', 'Capella University Corporate', 'Saatva, Inc', '8982937 CANADA INC', 'Salt Branding', 'Keiser University.']\n",
      "Customer\n",
      "3 0\n",
      "Houzz Inc.\n",
      "3 1\n",
      "Selectcomfort.com\n",
      "3 2\n",
      "Natural Intelligence, Inc.\n",
      "3 3\n",
      "*\n",
      "3 4\n",
      "Missing Value in Table Number: 1\n",
      "Check Column: Customer, Advertiser Number: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_spend_performing_advertisers():\n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[10], y_offsets[10]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'Top Spend Performing Customers':\n",
    "        print (\"Cannot find heading: Top Spend Performing Customers\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[10], y_offsets[10], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[10] + widths[10] - 1, y_offsets[10] + heights[10] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        top_spend_performing_advertisers_df = get_dataframe(start_cell, end_cell)\n",
    "        \n",
    "        # return top_spend_performing_advertisers_df\n",
    "        \n",
    "        if validate_advertiser_metrics(top_spend_performing_advertisers_df, 1) is False:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "top_spend_performing_advertisers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
