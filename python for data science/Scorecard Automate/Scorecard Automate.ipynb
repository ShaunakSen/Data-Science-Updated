{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scorecard Automation\n",
    "\n",
    "#### General Outline\n",
    "\n",
    "- First find **offset**\n",
    "- Check date\n",
    "- Read tables one by one\n",
    "- check for missing tables\n",
    "- Check data in each tabel\n",
    "- Check for missing data\n",
    "- Check if charts exist\n",
    "- Validate data with rnramd\n",
    "\n",
    "___\n",
    "\n",
    "**Write function to determine which sheet contains which data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of offsets\n",
    "\n",
    "> Network Summary Heading : 3\n",
    "\n",
    "> Bing O&O Core Browse:\n",
    "\n",
    "---\n",
    "\n",
    "**Make these global vars so that they can be changed anytime**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_offsets = [0, 21, 29, 1, 19, 27, 35, -1, -1, -1, 1, -14, -14]\n",
    "\n",
    "y_offsets = [6, 6, 6, 18, 18, 18, 18, -1, -1, -1, 61, 75, 89]\n",
    "widths = [7, 7, 7, 5, 5, 5, 2, -1, -1, -1, 12, 25, 25]\n",
    "\n",
    "extra_paddings = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 13]\n",
    "\n",
    "heights = [10, 10, 10, 8, 8, 8, 8, -1, -1, -1, 12, 12, 12]\n",
    "\n",
    "\n",
    "# make this into a list for each adv table\n",
    "max_allowable_perc_adv = 1000\n",
    "\n",
    "segment_names = ['Strategic/Tier 1', 'Mid Market/Tier 2', 'Scale/Tier 3', 'Channel Partner']\n",
    "\n",
    "if not(len(x_offsets) == len(y_offsets) == len(widths) == len(heights)):\n",
    "    print (\"Table metadata not consistent!\")\n",
    "    raise InterruptedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNRAMD Config Properties\n",
    "---\n",
    "\n",
    "Follow similar structure to NWSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnr_x_offsets = [0]\n",
    "\n",
    "rnr_y_offsets = [60]\n",
    "rnr_widths = [5]\n",
    "\n",
    "rnr_extra_paddings = [0]\n",
    "\n",
    "rnr_heights = [7]\n",
    "\n",
    "\n",
    "# make this into a list for each adv table\n",
    "rnr_max_allowable_perc_adv = 1000\n",
    "\n",
    "rnr_segment_names = ['Strategic/Tier 1', 'Mid Market/Tier 2', 'Scale/Tier 3', 'Channel Partner']\n",
    "\n",
    "if not(len(rnr_x_offsets) == len(rnr_y_offsets) == len(rnr_widths) == len(rnr_heights)):\n",
    "    print (\"Table metadata not consistent!\")\n",
    "    raise InterruptedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Development mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "print (platform.system())\n",
    "\n",
    "dev_mode = platform.system()\n",
    "\n",
    "if dev_mode == \"Linux\":\n",
    "    root_path = \"/media/shaunak/New Volume/my_projects/data science updated/python for data science/Scorecard Automate/data/\"\n",
    "elif dev_mode == \"Windows\":\n",
    "    root_path = \"D:/data_science-master/python for data science/Scorecard Automate/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import quandl\n",
    "import datetime\n",
    "\n",
    "wb = openpyxl.load_workbook(filename=root_path + 'data.xlsx', \n",
    "                   read_only=True)\n",
    "sheet_nw_sc = wb['Sheet4']\n",
    "\n",
    "data_rows = []\n",
    "for row in sheet_nw_sc['W10':'AC18']:\n",
    "    data_cols = []\n",
    "    for cell in row:\n",
    "        data_cols.append(cell.value)\n",
    "    data_rows.append(data_cols)\n",
    "\n",
    "    \n",
    "nw_sc_df = pd.DataFrame(data_rows)\n",
    "\n",
    "nw_sc_df.set_index(0, inplace=True)\n",
    "\n",
    "print (nw_sc_df)\n",
    "\n",
    "\"\"\"\n",
    "for row in sheet_nw_sc.iter_rows(min_row=21,min_col=23, max_col=30, max_row=25):\n",
    "    for cell in row:\n",
    "        print cell.value\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "wb = openpyxl.load_workbook(filename=root_path + 'data.xlsx', \n",
    "                   read_only=True)\n",
    "sheet_nw_sc = wb['Sheet6']\n",
    "\n",
    "data_rows = []\n",
    "for row in sheet_nw_sc['A74':'E80']:\n",
    "    data_cols = []\n",
    "    for cell in row:\n",
    "        data_cols.append(cell.value)\n",
    "    data_rows.append(data_cols)\n",
    "\n",
    "    \n",
    "nw_sc_df = pd.DataFrame(data_rows)\n",
    "\n",
    "nw_sc_df.set_index(0, inplace=True)\n",
    "\n",
    "print (nw_sc_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the NWSC file + determining offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "\n",
    "base_cell = 'W3'\n",
    "\n",
    "network_sc_date_as_date = \"\"\n",
    "\n",
    "workbook = openpyxl.load_workbook(filename = root_path + 'data3.xlsx', \n",
    "                   read_only=False)\n",
    "\n",
    "network_sc_sheet = workbook['Sheet4']\n",
    "\n",
    "\n",
    "print (network_sc_sheet.merged_cell_ranges)\n",
    "\n",
    "first_heading = str(network_sc_sheet['W3'].value)\n",
    "\n",
    "\n",
    "\n",
    "print (first_heading.strip('-'))\n",
    "\n",
    "\n",
    "if first_heading is None or first_heading.split('-')[0].strip() != 'SEARCH BG SCORECARD':\n",
    "    # print first_heading.split('-')[0].strip()\n",
    "    print (\"offset to be changed\")\n",
    "    \n",
    "    first_heading = str(network_sc_sheet['W14'].value)\n",
    "    \n",
    "    if first_heading.split('-')[0].strip() == 'SEARCH BG SCORECARD':\n",
    "        offset = 11\n",
    "        print (\"Offset changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offset changed at this step -- Move to separate function\n",
    "\n",
    "#### Validating the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_date():\n",
    "    global offset\n",
    "    global base_cell\n",
    "    global network_sc_sheet\n",
    "    global network_sc_date_as_date\n",
    "    # base cell = W3\n",
    "    base_cell_num = int(base_cell[1:len(base_cell)])\n",
    "    base_cell_num += offset\n",
    "    \n",
    "    cell_ref = base_cell[0] + str(base_cell_num)\n",
    "    \n",
    "    print (cell_ref)\n",
    "    \n",
    "    # Modifying the base cell\n",
    "    \n",
    "    base_cell = cell_ref\n",
    "    \n",
    "    first_heading = network_sc_sheet[cell_ref].value\n",
    "    \n",
    "    try:\n",
    "        network_sc_date = first_heading.split('-')[1]\n",
    "        network_sc_date = network_sc_date.strip()\n",
    "        \n",
    "        print (network_sc_date)\n",
    "        \n",
    "        network_sc_date_as_date = datetime.datetime.strptime(network_sc_date, \"%B %d, %Y\").date()\n",
    "        \n",
    "        # print network_sc_date_as_date\n",
    "        \n",
    "        current_date = datetime.date.today()\n",
    "        \n",
    "        # print datetime.date.today()\n",
    "        \n",
    "        # print network_sc_date_as_date + datetime.timedelta(days = 33) == datetime.date.today()\n",
    "        \n",
    "        days_lag = abs(current_date - network_sc_date_as_date).days\n",
    "        \n",
    "        if days_lag == 0:\n",
    "            print (\"Dates Validated!\")\n",
    "            return True\n",
    "        else:\n",
    "            print (\"Scorecard is behind by: \", days_lag, \"days\")\n",
    "            return False\n",
    "        \n",
    "    except IndexError:\n",
    "        print (\"There was some problem parsing the date\")\n",
    "        return False\n",
    "    \n",
    "validate_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Fuction to get cell reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cell_ref(increment):\n",
    "    global base_cell\n",
    "    base_cell\n",
    "    base_cell_int = int(base_cell[1:len(base_cell)])\n",
    "    base_cell_int += increment\n",
    "    new_cell_ref = base_cell[0] + str(base_cell_int)\n",
    "    return new_cell_ref\n",
    "\n",
    "get_cell_ref(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to read in cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(cell_ref):\n",
    "    data = network_sc_sheet[cell_ref].value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to traverse cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cols = []\n",
    "\n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append(chr(col))\n",
    "\n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('A' + chr(col))\n",
    "    \n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('B' + chr(col))\n",
    "    \n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('C' + chr(col))\n",
    "    \n",
    "def traverse_cells(cell, incx, incy, mode=0):\n",
    "    if mode == 0:\n",
    "        # w3\n",
    "        column_number = cell[0]\n",
    "        row_number = int(cell[1:len(cell)])\n",
    "    elif mode == 1:\n",
    "        #ab1\n",
    "        column_number = cell[0:2]\n",
    "        row_number = int(cell[2:len(cell)])\n",
    "        \n",
    "    index_of_col = list_of_cols.index(column_number)\n",
    "    index_of_col += incx\n",
    "    new_col = list_of_cols[index_of_col]\n",
    "    row_number += incy\n",
    "    new_cell_ref = new_col + str(row_number)\n",
    "    \n",
    "    return new_cell_ref\n",
    "    \n",
    "    \n",
    "    \n",
    "traverse_cells('BZ1', 5, 28, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to get a set of cells and return a pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(start_cell, end_cell):\n",
    "    data_rows = []\n",
    "    for row in network_sc_sheet[start_cell: end_cell]:\n",
    "        data_cols = []\n",
    "        for cell in row:\n",
    "            data_cols.append(cell.value)\n",
    "        data_rows.append(data_cols)\n",
    "    coverted_df = pd.DataFrame(data_rows) \n",
    "    return coverted_df\n",
    "\n",
    "get_dataframe('AZ20', 'BF29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_rnr(start_cell, end_cell):\n",
    "    data_rows = []\n",
    "    for row in sheet_rnr_amd[start_cell: end_cell]:\n",
    "        data_cols = []\n",
    "        for cell in row:\n",
    "            data_cols.append(cell.value)\n",
    "        data_rows.append(data_cols)\n",
    "    coverted_df = pd.DataFrame(data_rows) \n",
    "    return coverted_df\n",
    "\n",
    "# get_dataframe_rnr('A74', 'E80')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to extract numeric value from character string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "def convert_to_numeric(number_str):\n",
    "    print (\"String in func:\", number_str)\n",
    "    \n",
    "    \n",
    "    if dev_mode == 'linux':\n",
    "        if type(number_str) == type(b'mini'):\n",
    "            number_str = number_str.decode()\n",
    "    list_of_chars = list(str(number_str))\n",
    "    \n",
    "    first_num_index = -1\n",
    "    \n",
    "    was_int = 0\n",
    "    \n",
    "    last_num_index = len(list_of_chars)-1\n",
    "    for x in range(0, len(list_of_chars)):\n",
    "        try:\n",
    "            char_as_num = int(list_of_chars[x])\n",
    "            was_int = 1\n",
    "        except ValueError:\n",
    "            was_int = 0\n",
    "        if was_int == 1:\n",
    "            break\n",
    "            \n",
    "    first_num_index = x\n",
    "    # print first_num_index\n",
    "    \n",
    "    was_char = 1\n",
    "    \n",
    "    for x in range(last_num_index, -1, -1):\n",
    "        try:\n",
    "            char_as_num = int(list_of_chars[x])\n",
    "            was_char = 0\n",
    "        except ValueError:\n",
    "            last_num_index -= 1\n",
    "            was_char = 1\n",
    "        if was_char == 0:\n",
    "            break\n",
    "    last_num_index = x\n",
    "    # print last_num_index\n",
    "    \n",
    "    if (last_num_index < first_num_index):\n",
    "        return False\n",
    "    else:\n",
    "        return float(\"\".join(list_of_chars[first_num_index: last_num_index+1]))\n",
    "    \n",
    "convert_to_numeric('93.4¢')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base cell ref changed at this step -- Move to separate function\n",
    "\n",
    "#### Dates validated\n",
    "\n",
    "Check for Network Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to check missing and zero values in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to check 1st table data\n",
    "\n",
    "> Make it resuable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_smart_pricing_data(first_table_df):\n",
    "    \n",
    "    # maybe date check should be done here\n",
    "    \n",
    "    # first_table_df[3][1] = 0\n",
    "    # first_table_df[2][3] = '*'\n",
    "    # first_table_df[2][4] = None\n",
    "    \n",
    "    # check for missing data\n",
    "\n",
    "    # print first_table_df.columns\n",
    "\n",
    "    for column_index in first_table_df.columns[1:]:\n",
    "        column_values = first_table_df[column_index][1:].tolist()\n",
    "        if check_missing_and_zero_values(column_values) is False:\n",
    "            print (\"Smart Pricing Data Missing\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    print (\"Smart Pricing data ok\")\n",
    "    return True\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** When we convert to utf-8 in python 3 it will get converted as a byte string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "def check_missing_and_zero_values(column_list):\n",
    "    for value in column_list:\n",
    "        print (value)\n",
    "        if isinstance(value, numbers.Number) is False:\n",
    "            if value is None:\n",
    "                print (\"Missing values in First Table\")\n",
    "                return False\n",
    "            else:\n",
    "\n",
    "                # not a number \n",
    "                # maybe: '$#%$%'\n",
    "                try:\n",
    "                    length = len(value)\n",
    "                    if length < 2:\n",
    "                        print (\"Missing values in First Table\")\n",
    "                        return False\n",
    "                    else:\n",
    "                        # problem here: what if u cant encode??\n",
    "                        if dev_mode == 'Linux':\n",
    "                            value = value.encode('utf-8')\n",
    "                        else:\n",
    "                            value = value.encode('utf-8')\n",
    "                        if convert_to_numeric(value) is False:\n",
    "                            print (\"Missing values in First Table\")\n",
    "                            return False\n",
    "\n",
    "                except:\n",
    "                    print (\"Unknown stuff in First Table\")\n",
    "                    return False\n",
    "        else:\n",
    "            # number\n",
    "            number_as_float = float(value)\n",
    "            if float(value) == 0.0:\n",
    "                print (\"Zero values in First Table\")\n",
    "                return False\n",
    "                \n",
    "    return True\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_table_data(table_df, table_number):\n",
    "    \n",
    "    # maybe date check should be done here\n",
    "    \n",
    "    # first_table_df[3][1] = 0\n",
    "    # first_table_df[2][3] = '*'\n",
    "    # first_table_df[2][4] = None\n",
    "    \n",
    "    height_of_table = heights[table_number - 1]\n",
    "    width_of_table = widths[table_number - 1]\n",
    "    \n",
    "    if table_df.shape == (height_of_table, width_of_table):\n",
    "        \n",
    "        # check for missing data\n",
    "        \n",
    "        if table_number!= 7:\n",
    "            table_df.drop([4], axis = 1, inplace = True)\n",
    "            # print first_table_df.columns\n",
    "        \n",
    "        for column_index in table_df.columns[1:]:\n",
    "            column_values = table_df[column_index][1:].tolist()\n",
    "            if check_missing_and_zero_values(column_values) is False:\n",
    "                return False\n",
    "    \n",
    "\n",
    "        \n",
    "        print (\"Data ok for table number:\", table_number)\n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print (\"Dimension of does not match for table number:\", table_number)\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def organic_metrics_validation(first_table_df):\n",
    "    \n",
    "    if first_table_df.shape == (10, 6):\n",
    "        \n",
    "        required_column = first_table_df[1][1:].tolist()\n",
    "        print (required_column)\n",
    "        \n",
    "        organic_metrics = required_column[:6]\n",
    "        non_organic_metrics = required_column[6:]\n",
    "        \n",
    "        oRev = organic_metrics[5]\n",
    "        oVol = organic_metrics[4]\n",
    "        Rev = non_organic_metrics[0]\n",
    "        Vol = non_organic_metrics[1]\n",
    "        \n",
    "        print (oRev, oVol, Rev, Vol)\n",
    "        \n",
    "        # test case: oRev = 10.00\n",
    "        \n",
    "        oRev = convert_to_numeric(oRev)\n",
    "        oVol = convert_to_numeric(oVol)\n",
    "        Rev = convert_to_numeric(Rev)\n",
    "        Vol = convert_to_numeric(Vol)\n",
    "        \n",
    "        print (oRev, oVol, Rev, Vol)\n",
    "        \n",
    "        if Rev < oRev or Vol < oVol:\n",
    "            print (\"Organic metrics greater than combined metrics which is not possible\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print (\"Dimension of First Table does not match\")\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Network Summary First table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_summary_first_table():\n",
    "    cell_ref = get_cell_ref(3)\n",
    "    first_heading = str(read_data(cell_ref))\n",
    "    # print first_heading\n",
    "    \n",
    "    if first_heading.strip() != 'NETWORK SUMMARY':\n",
    "        print (\"Cannot find heading: NETWORK SUMMARY\")\n",
    "        return False\n",
    "    else:\n",
    "        # all ok until now\n",
    "        # try to find second heading\n",
    "        \n",
    "        second_heading = str(read_data(get_cell_ref(5)))\n",
    "        if second_heading.strip() != 'Bing O&O Core Browse':\n",
    "            print (\"Cannot find heading: Bing O&O Core Browse\")\n",
    "            return False\n",
    "        else:\n",
    "            # read in the range of cells\n",
    "            start_cell = get_cell_ref(6)\n",
    "            # print start_cell\n",
    "            \n",
    "            end_cell = traverse_cells(start_cell, widths[0]-1, heights[0]-1, 0)\n",
    "            # print end_cell\n",
    "            \n",
    "            network_summary_first_table_df = get_dataframe(start_cell, end_cell)\n",
    "            \n",
    "            \n",
    "            network_summary_first_table_date = network_summary_first_table_df.loc[0][1]\n",
    "            network_summary_first_table_date = datetime.datetime.date(network_summary_first_table_date)\n",
    "            \n",
    "            # print network_sc_date_as_date\n",
    "            \n",
    "            # print network_summary_first_table_date\n",
    "            \n",
    "            if (network_sc_date_as_date - network_summary_first_table_date).days == 1:\n",
    "                print (\"Dates validated in First Table\")\n",
    "                \n",
    "                # check table data\n",
    "                if check_table_data(network_summary_first_table_df, 1) is False:\n",
    "                    return False\n",
    "                \n",
    "                if organic_metrics_validation(network_summary_first_table_df) is False:\n",
    "                    return False\n",
    "            \n",
    "            else:\n",
    "                print (\"Dates not validated in First Table\")\n",
    "                return False\n",
    "            \n",
    "            print (\"All ok in First Table!!\")\n",
    "            \n",
    "            return True\n",
    "    \n",
    "\n",
    "network_summary_first_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Nw Summary Second Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_summary_second_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[1], y_offsets[1]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    if second_heading.strip() != 'Yahoo O&O':\n",
    "        print (\"Cannot find heading: Yahoo O&O\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[1], y_offsets[1], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[1] + widths[1] - 1, y_offsets[1] + heights[1] - 1, 0)\n",
    "\n",
    "        network_summary_second_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_second_table_date = network_summary_second_table_df.loc[0][1]\n",
    "        network_summary_second_table_date = datetime.datetime.date(network_summary_second_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_second_table_date).days == 1:\n",
    "            print (\"Dates validated in Second Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_second_table_df, 2) is False:\n",
    "                return False\n",
    "\n",
    "        else:\n",
    "            print (\"Dates not validated in Second Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Second Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_second_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check NW Summary Third Table (Smart Pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_summary_third_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[2], y_offsets[2]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    if second_heading.strip() != 'Yahoo Syndication':\n",
    "        print (\"Cannot find heading: Yahoo Syndication\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[2], y_offsets[2], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[2] + widths[2] - 1, y_offsets[2] + heights[2] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_third_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_third_table_date = network_summary_third_table_df.loc[0][1]\n",
    "        network_summary_third_table_date = datetime.datetime.date(network_summary_third_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_third_table_date).days == 1:\n",
    "            print (\"Dates validated in Third Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_third_table_df, 3) is False:\n",
    "                if check_smart_pricing_data(network_summary_third_table_df) is False:\n",
    "                    print (\"Samrt Pricing Data not available\")\n",
    "                    return False\n",
    "                else:\n",
    "                    print (\"Missing values in Third Table\")\n",
    "                    return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Third Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Third Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_third_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_summary_fourth_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[3], y_offsets[3]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'AOL O&O Guaranty (PC Only)':\n",
    "        print (\"Cannot find heading: AOL O&O Guaranty (PC Only)\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[3], y_offsets[3], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[3] + widths[3] - 1, y_offsets[3] + heights[3] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_fourth_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_fourth_table_date = network_summary_fourth_table_df.loc[0][1]\n",
    "        network_summary_fourth_table_date = datetime.datetime.date(network_summary_fourth_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_fourth_table_date).days == 1:\n",
    "            print (\"Dates validated in Fourth Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_fourth_table_df,4) is False:\n",
    "                return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Fourth Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Fourth Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_fourth_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_summary_fifth_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[4], y_offsets[4]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'AOL O&O':\n",
    "        print (\"Cannot find heading: AOL O&O\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[4], y_offsets[4], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[4] + widths[4] - 1, y_offsets[4] + heights[4] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_fifth_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_fifth_table_date = network_summary_fifth_table_df.loc[0][1]\n",
    "        network_summary_fifth_table_date = datetime.datetime.date(network_summary_fifth_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_fifth_table_date).days == 1:\n",
    "            print (\"Dates validated in Fifth Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_fifth_table_df, 5) is False:\n",
    "                return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Fifth Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Fifth Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_fifth_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_summary_sixth_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[5], y_offsets[5]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'AOL Syndication':\n",
    "        print (\"Cannot find heading: AOL Syndication\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[5], y_offsets[5], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[5] + widths[5] - 1, y_offsets[5] + heights[5] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_sixth_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_sixth_table_date = network_summary_sixth_table_df.loc[0][1]\n",
    "        network_summary_sixth_table_date = datetime.datetime.date(network_summary_sixth_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_sixth_table_date).days == 1:\n",
    "            print (\"Dates validated in Fifth Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_sixth_table_df, 6) is False:\n",
    "                return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Fifth Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Fifth Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_sixth_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_summary_seventh_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[6], y_offsets[6]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'AOL (O&O and Syndication)':\n",
    "        print (\"Cannot find heading: AOL Syndication\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[6], y_offsets[6], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[6] + widths[6] - 1, y_offsets[6] + heights[6] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_seventh_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_seventh_table_date = network_summary_seventh_table_df.loc[0][1]\n",
    "        network_summary_seventh_table_date = datetime.datetime.date(network_summary_seventh_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_seventh_table_date).days == 1:\n",
    "            print (\"Dates validated in Fifth Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_table_data(network_summary_seventh_table_df, 7) is False:\n",
    "                return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Seventh Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Seventh Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_seventh_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Network Summary In-place validation done\n",
    "\n",
    "#### Advertiser Metrics Validation\n",
    "\n",
    "- Check if each segment is there\n",
    "- No missing values\n",
    "- No 0 values in performing 1st 2 segments\n",
    "- No abrubt % changes\n",
    "\n",
    "Note: special chars might come up in Adv names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Function: Custom Error Generation Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_error_message(table_number, column_number, adv_number):\n",
    "    \n",
    "    segment_number = int(((column_number+3)/3)-1)\n",
    "    \n",
    "    \n",
    "    if (column_number+3)%3 == 0:\n",
    "         \n",
    "        print (\"Check Segement: \", segment_names[segment_number], \"Check Column: Customer, Advertiser Number:\", adv_number)\n",
    "    elif (column_number+3)%3 == 1:\n",
    "        print (\"Check Segement: \", segment_names[segment_number], \"Check Column: Spend, Advertiser Number:\", adv_number)\n",
    "    else:\n",
    "        print (\"Check Segement: \", segment_names[segment_number], \"Check Column: Spend WoW, Advertiser Number:\", adv_number)\n",
    "        \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "def check_missing_values(column_list, column_number, table_number):\n",
    "    \n",
    "    # Modify these functions to help know where EXACTLY error occured\n",
    "    \n",
    "    # Missing value in Customer:Adv no:5\n",
    "    \n",
    "    \n",
    "    print (\"Col list in func:\", column_list)\n",
    "    \n",
    "    \n",
    "    adv_number = 0\n",
    "    for value in column_list:\n",
    "        print (value)\n",
    "        print (column_number, adv_number)\n",
    "        if isinstance(value, numbers.Number) is False:\n",
    "            if value is None:\n",
    "                print (\"Missing Value in Table Number:\", table_number)\n",
    "                generate_error_message(table_number, column_number, adv_number)\n",
    "                return False\n",
    "            else:\n",
    "        \n",
    "                try:\n",
    "                    length = len(value)\n",
    "                    if length < 2:\n",
    "                        print (\"Missing Value in Table Number:\", table_number)\n",
    "                        generate_error_message(table_number, column_number, adv_number)\n",
    "                        return False\n",
    "                except:\n",
    "                    print (\"Unknown Stuff in Table Number:\", table_number)\n",
    "                    return False\n",
    "        adv_number += 1\n",
    "                \n",
    "    return True\n",
    "\n",
    "\n",
    "import numbers\n",
    "\n",
    "def check_zero_values(column_list, column_number, table_number):\n",
    "    \n",
    "    adv_number = 1\n",
    "    for value in column_list:\n",
    "        print (value)\n",
    "        print (column_number, adv_number)\n",
    "        if isinstance(value, numbers.Number) is False:\n",
    "            \n",
    "            # not a number: not possible\n",
    "            print (\"Advertiser Metric Spend should be numerical\")\n",
    "            generate_error_message(table_number, column_number, adv_number)\n",
    "            return False\n",
    "            \n",
    "        else:\n",
    "            # number\n",
    "            number_as_float = float(value)\n",
    "            if number_as_float == 0.0:\n",
    "                print (\"Zero value in First 2 Segemnts!\")\n",
    "                generate_error_message(table_number, column_number, adv_number)\n",
    "                if table_number < 3:\n",
    "                    return False\n",
    "            \n",
    "        adv_number += 1\n",
    "                \n",
    "    return True\n",
    "\n",
    "def check_abrupt_values(column_list, column_number, table_number):\n",
    "    \n",
    "    adv_number = 1\n",
    "    for value in column_list:\n",
    "        print (value)\n",
    "        if isinstance(value, numbers.Number) is False:\n",
    "            \n",
    "            # not a number: not possible\n",
    "            print (\"Advertiser Metric Spend WoW should be numerical\")\n",
    "            generate_error_message(table_number, column_number, adv_number)\n",
    "            return False\n",
    "            \n",
    "        else:\n",
    "            # number\n",
    "            number_as_float = float(value)\n",
    "            if number_as_float*100 > 200:\n",
    "                print (\"Spend WoW % > Allowable %:\", max_allowable_perc_adv)\n",
    "                generate_error_message(table_number, column_number, adv_number)\n",
    "                \n",
    "                # dont return False , just alert user\n",
    "                # return False\n",
    "            \n",
    "        adv_number += 1\n",
    "                \n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def validate_advertiser_metrics(adv_df, table_number):\n",
    "    \n",
    "    # check if each segement is there of not\n",
    "    \n",
    "    # test case: adv_df[0][0] = \"\"\n",
    "    try:\n",
    "        \n",
    "        # get segment names\n",
    "        \n",
    "        first_segment = adv_df[0][0].strip()\n",
    "        second_segment = adv_df[3][0].strip()\n",
    "        third_segement = adv_df[6][0].strip()\n",
    "        fourth_segment = adv_df[9][0].strip()\n",
    "    \n",
    "        print (first_segment, second_segment, third_segement, fourth_segment)\n",
    "\n",
    "        # validate segment names\n",
    "        \n",
    "        if first_segment != segment_names[0] or second_segment != segment_names[1] or third_segement != segment_names[2] or fourth_segment != segment_names[3]:\n",
    "            print (\"Segment Names not matching in Advertiser Metrics Table Number:\", table_number)\n",
    "            return False\n",
    "    except:\n",
    "        print(\"Unknown stuff in Advertiser Metrics Table Number:\", table_number)\n",
    "        return False\n",
    "    \n",
    "    # check for misisng values for entire df\n",
    "    \n",
    "    for column_index in adv_df.columns:\n",
    "            column_values = adv_df[column_index][1:].tolist()\n",
    "            if check_missing_values(column_values, column_index, table_number) is False:\n",
    "                return False\n",
    "            \n",
    "    # check for 0 values in first 2 segments\n",
    "    \n",
    "        # check for 0 value in spend\n",
    "        # check for abrupt % change in Spend WoW\n",
    "        \n",
    "        \n",
    "    # 1, 4, \n",
    "\n",
    "    \n",
    "    \n",
    "    for column_index in range(1, 5, 3):\n",
    "        column_values = adv_df[column_index][2:].tolist()\n",
    "        if check_zero_values(column_values, column_index, table_number) is False:\n",
    "            return False\n",
    "        \n",
    "    # 2, 5, 8, 11\n",
    "        \n",
    "    for column_index in range(2, 12, 3):\n",
    "        column_values = adv_df[column_index][2:].tolist()\n",
    "        if check_abrupt_values(column_values, column_index, table_number) is False:\n",
    "            return False\n",
    "        \n",
    "    \n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_spend_performing_advertisers():\n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[10], y_offsets[10]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'Top Spend Performing Customers':\n",
    "        print (\"Cannot find heading: Top Spend Performing Customers\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[10], y_offsets[10], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[10] + widths[10] - 1, y_offsets[10] + heights[10] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        top_spend_performing_advertisers_df = get_dataframe(start_cell, end_cell)\n",
    "        \n",
    "        # return top_spend_performing_advertisers_df\n",
    "        \n",
    "        if validate_advertiser_metrics(top_spend_performing_advertisers_df, 1) is False:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "top_spend_performing_advertisers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_spend_DoD_advertisers():\n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[11], y_offsets[11]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'Top Spend Day Over Day Gainers Customers':\n",
    "        print (\"Cannot find heading: Top Spend Day Over Day Gainers Customers\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cell1\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[11], y_offsets[11], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[11] + widths[11] - 1, y_offsets[11] + heights[11] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        top_spend_DoD_gainer_advertisers_df = get_dataframe(start_cell, end_cell)\n",
    "        \n",
    "        for x in range(1, extra_paddings[11]+1):\n",
    "            del top_spend_DoD_gainer_advertisers_df[x]\n",
    "        \n",
    "        \n",
    "        actual_width = widths[11] - extra_paddings[11]\n",
    "        \n",
    "        top_spend_DoD_gainer_advertisers_df.columns = list(range(actual_width))\n",
    "        \n",
    "        # we get the clean df at this stage\n",
    "                \n",
    "        if validate_advertiser_metrics(top_spend_DoD_gainer_advertisers_df, 2) is False:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "top_spend_DoD_advertisers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def top_spend_DoD_loser_advertisers():\n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[12], y_offsets[12]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    print(second_heading)\n",
    "    \n",
    "    if second_heading.strip() != 'Top Spend Day Over Day Losers Customers':\n",
    "        print (\"Cannot find heading: Top Spend Day Over Day Losers Customers\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cell1\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[12], y_offsets[12], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[12] + widths[12] - 1, y_offsets[12] + heights[12] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        top_spend_DoD_loser_advertisers_df = get_dataframe(start_cell, end_cell)\n",
    "        \n",
    "        for x in range(1, extra_paddings[12]+1):\n",
    "            del top_spend_DoD_loser_advertisers_df[x]\n",
    "        \n",
    "        \n",
    "        actual_width = widths[12] - extra_paddings[12]\n",
    "        \n",
    "        top_spend_DoD_loser_advertisers_df.columns = list(range(actual_width))\n",
    "        \n",
    "        # we get the clean df at this stage\n",
    "                        \n",
    "        if validate_advertiser_metrics(top_spend_DoD_loser_advertisers_df, 3) is False:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "top_spend_DoD_loser_advertisers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading RNRAMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wb = openpyxl.load_workbook(filename=root_path + 'data.xlsx', \n",
    "                   read_only=True)\n",
    "sheet_rnr_amd = wb['Sheet6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining Offset for RNRAMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_rnr = 0\n",
    "\n",
    "base_cell_rnr = 'A14'\n",
    "\n",
    "\n",
    "first_heading = str(sheet_rnr_amd[base_cell].value)\n",
    "\n",
    "\n",
    "print(first_heading)\n",
    "\n",
    "if first_heading is None or first_heading.split('-')[0].strip() != 'Bing O&O Core Organic (PC Browse & Tablet) Incl. Kindle':\n",
    "    # print first_heading.split('-')[0].strip()\n",
    "    print (\"offset to be changed\")\n",
    "    \n",
    "else:\n",
    "    print(\"No need to change offset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bing_rnr_table():\n",
    "    start_cell = traverse_cells(base_cell_rnr, rnr_x_offsets[0], rnr_y_offsets[0], 0)\n",
    "\n",
    "    end_cell = traverse_cells(base_cell_rnr, rnr_x_offsets[0] + rnr_widths[0] - 1, rnr_y_offsets[0] + rnr_heights[0] - 1, 0)\n",
    "\n",
    "    print (start_cell, end_cell)\n",
    "\n",
    "    rnr_bing_df = get_dataframe_rnr(start_cell, end_cell)\n",
    "    \n",
    "    return rnr_bing_df\n",
    "    \n",
    "    \n",
    "read_bing_rnr_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
