{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scorecard Automation\n",
    "\n",
    "#### General Outline\n",
    "\n",
    "- First find **offset**\n",
    "- Check date\n",
    "- Read tables one by one\n",
    "- check for missing tables\n",
    "- Check data in each tabel\n",
    "- Check for missing data\n",
    "- Check if charts exist\n",
    "- Validate data with rnramd\n",
    "\n",
    "___\n",
    "\n",
    "**Write function to determine which sheet contains which data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of offsets\n",
    "\n",
    "> Network Summary Heading : 3\n",
    "\n",
    "> Bing O&O Core Browse:\n",
    "\n",
    "---\n",
    "\n",
    "**Make these global vars so that they can be changed anytime**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-316e84e6299b>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-316e84e6299b>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    raise InterruptedError:\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x_offsets = [0, 21, 29, 1]\n",
    "\n",
    "y_offsets = [6, 6, 6, 17]\n",
    "widths = [7, 7, 7, 5]\n",
    "\n",
    "heights = [10, 10, 10]\n",
    "\n",
    "if not(len(x_offsets) == len(y_offsets) == len(widths) == len(heights)):\n",
    "    print (\"Table metadata not consistent!\")\n",
    "    raise InterruptedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Development mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print (platform.system())\n",
    "\n",
    "dev_mode = platform.system()\n",
    "\n",
    "if dev_mode == \"Linux\":\n",
    "    root_path = \"/media/shaunak/New Volume/my_projects/data science updated/python for data science/Scorecard Automate/data/\"\n",
    "elif dev_mode == \"Windows\":\n",
    "    root_path = \"D:/data_science-master/python for data science/Scorecard Automate/data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             1       2       3     4       5       6\n",
      "0                                                   \n",
      "oRPM     72.81 -0.0228 -0.0254  None  0.1085  0.1562\n",
      "oPPC     92.5¢ -0.0106 -0.0194  None  0.0233  0.1022\n",
      "oCY      0.079 -0.0123 -0.0061  None  0.0833  0.0490\n",
      "oMLIY     0.56 -0.0251 -0.0093  None -0.0892 -0.1155\n",
      "oVol     117mm -0.0219  0.0063  None  0.0200  0.0417\n",
      "oRev   $8.52mm -0.0442 -0.0193  None  0.1306  0.2045\n",
      "Rev    $8.55mm -0.0442 -0.0190  None  0.1327  0.1995\n",
      "Vol      129mm -0.0437 -0.0092  None  0.0632  0.0795\n",
      "RPM      66.52 -0.0005 -0.0099  None  0.0651  0.1111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor row in sheet_nw_sc.iter_rows(min_row=21,min_col=23, max_col=30, max_row=25):\\n    for cell in row:\\n        print cell.value\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import quandl\n",
    "import datetime\n",
    "\n",
    "wb = openpyxl.load_workbook(filename=root_path + 'data.xlsx', \n",
    "                   read_only=True)\n",
    "sheet_nw_sc = wb['Sheet4']\n",
    "\n",
    "data_rows = []\n",
    "for row in sheet_nw_sc['W10':'AC18']:\n",
    "    data_cols = []\n",
    "    for cell in row:\n",
    "        data_cols.append(cell.value)\n",
    "    data_rows.append(data_cols)\n",
    "\n",
    "    \n",
    "nw_sc_df = pd.DataFrame(data_rows)\n",
    "\n",
    "nw_sc_df.set_index(0, inplace=True)\n",
    "\n",
    "print (nw_sc_df)\n",
    "\n",
    "\"\"\"\n",
    "for row in sheet_nw_sc.iter_rows(min_row=21,min_col=23, max_col=30, max_row=25):\n",
    "    for cell in row:\n",
    "        print cell.value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the file + determining offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "offset to be changed\n",
      "Offset changed\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "\n",
    "base_cell = 'W3'\n",
    "\n",
    "network_sc_date_as_date = \"\"\n",
    "\n",
    "workbook = openpyxl.load_workbook(filename = root_path + 'data3.xlsx', \n",
    "                   read_only=True)\n",
    "\n",
    "network_sc_sheet = workbook['Sheet4']\n",
    "\n",
    "first_heading = str(network_sc_sheet['W3'].value)\n",
    "\n",
    "print (first_heading.strip('-'))\n",
    "\n",
    "\n",
    "if first_heading is None or first_heading.split('-')[0].strip() != 'SEARCH BG SCORECARD':\n",
    "    # print first_heading.split('-')[0].strip()\n",
    "    print (\"offset to be changed\")\n",
    "    \n",
    "    first_heading = str(network_sc_sheet['W14'].value)\n",
    "    \n",
    "    if first_heading.split('-')[0].strip() == 'SEARCH BG SCORECARD':\n",
    "        offset = 11\n",
    "        print (\"Offset changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offset changed at this step -- Move to separate function\n",
    "\n",
    "#### Validating the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W14\n",
      "January 3, 2018\n",
      "Scorecard is behind by:  38 days\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_date():\n",
    "    global offset\n",
    "    global base_cell\n",
    "    global network_sc_sheet\n",
    "    global network_sc_date_as_date\n",
    "    # base cell = W3\n",
    "    base_cell_num = int(base_cell[1:len(base_cell)])\n",
    "    base_cell_num += offset\n",
    "    \n",
    "    cell_ref = base_cell[0] + str(base_cell_num)\n",
    "    \n",
    "    print (cell_ref)\n",
    "    \n",
    "    # Modifying the base cell\n",
    "    \n",
    "    base_cell = cell_ref\n",
    "    \n",
    "    first_heading = network_sc_sheet[cell_ref].value\n",
    "    \n",
    "    try:\n",
    "        network_sc_date = first_heading.split('-')[1]\n",
    "        network_sc_date = network_sc_date.strip()\n",
    "        \n",
    "        print (network_sc_date)\n",
    "        \n",
    "        network_sc_date_as_date = datetime.datetime.strptime(network_sc_date, \"%B %d, %Y\").date()\n",
    "        \n",
    "        # print network_sc_date_as_date\n",
    "        \n",
    "        current_date = datetime.date.today()\n",
    "        \n",
    "        # print datetime.date.today()\n",
    "        \n",
    "        # print network_sc_date_as_date + datetime.timedelta(days = 33) == datetime.date.today()\n",
    "        \n",
    "        days_lag = abs(current_date - network_sc_date_as_date).days\n",
    "        \n",
    "        if days_lag == 0:\n",
    "            print (\"Dates Validated!\")\n",
    "            return True\n",
    "        else:\n",
    "            print (\"Scorecard is behind by: \", days_lag, \"days\")\n",
    "            return False\n",
    "        \n",
    "    except IndexError:\n",
    "        print (\"There was some problem parsing the date\")\n",
    "        return False\n",
    "    \n",
    "validate_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility Fuction to get cell reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W17'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_cell_ref(increment):\n",
    "    global base_cell\n",
    "    base_cell\n",
    "    base_cell_int = int(base_cell[1:len(base_cell)])\n",
    "    base_cell_int += increment\n",
    "    new_cell_ref = base_cell[0] + str(base_cell_int)\n",
    "    return new_cell_ref\n",
    "\n",
    "get_cell_ref(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to read in cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(cell_ref):\n",
    "    data = network_sc_sheet[cell_ref].value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to traverse cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CE29'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_cols = []\n",
    "\n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append(chr(col))\n",
    "\n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('A' + chr(col))\n",
    "    \n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('B' + chr(col))\n",
    "    \n",
    "for col in range(ord('A'), ord('Z')+1):\n",
    "    list_of_cols.append('C' + chr(col))\n",
    "    \n",
    "def traverse_cells(cell, incx, incy, mode=0):\n",
    "    if mode == 0:\n",
    "        # w3\n",
    "        column_number = cell[0]\n",
    "        row_number = int(cell[1:len(cell)])\n",
    "    elif mode == 1:\n",
    "        #ab1\n",
    "        column_number = cell[0:2]\n",
    "        row_number = int(cell[2:len(cell)])\n",
    "        \n",
    "    index_of_col = list_of_cols.index(column_number)\n",
    "    index_of_col += incx\n",
    "    new_col = list_of_cols[index_of_col]\n",
    "    row_number += incy\n",
    "    new_cell_ref = new_col + str(row_number)\n",
    "    \n",
    "    return new_cell_ref\n",
    "    \n",
    "    \n",
    "    \n",
    "traverse_cells('BZ1', 5, 28, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to get a set of cells and return a pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>Δ01/01</td>\n",
       "      <td>Δ12/26</td>\n",
       "      <td>None</td>\n",
       "      <td>Δ2017</td>\n",
       "      <td>Δ2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RPM</td>\n",
       "      <td>30.68</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>-0.0505</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.6015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PPC</td>\n",
       "      <td>53.6¢</td>\n",
       "      <td>-0.0123</td>\n",
       "      <td>-0.0816</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.1081</td>\n",
       "      <td>0.1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CY</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2541</td>\n",
       "      <td>0.0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IY</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.2203</td>\n",
       "      <td>-0.3808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vol</td>\n",
       "      <td>30mm</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.1021</td>\n",
       "      <td>0.0199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rev</td>\n",
       "      <td>$0.91mm</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.6335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cCPAi</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>None</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rCPAi</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>None</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SP Disc</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.02pp</td>\n",
       "      <td>0.08pp</td>\n",
       "      <td>None</td>\n",
       "      <td>-11.69pp</td>\n",
       "      <td>-14.26pp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                    1       2       3     4         5         6\n",
       "0     None  2018-01-02 00:00:00  Δ01/01  Δ12/26  None     Δ2017     Δ2016\n",
       "1      RPM                30.68  0.0107 -0.0505  None    0.1186    0.6015\n",
       "2      PPC                53.6¢ -0.0123 -0.0816  None   -0.1081    0.1209\n",
       "3       CY                0.057  0.0233  0.0339  None    0.2541    0.0206\n",
       "4       IY                 3.41  0.0481  0.0269  None   -0.2203   -0.3808\n",
       "5      Vol                 30mm  0.2145  0.1917  None   -0.1021    0.0199\n",
       "6      Rev              $0.91mm  0.2275  0.1315  None    0.0044    0.6335\n",
       "7    cCPAi                    *       *       *  None         *         *\n",
       "8    rCPAi                    *       *       *  None         *         *\n",
       "9  SP Disc               0.0069  0.02pp  0.08pp  None  -11.69pp  -14.26pp"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_dataframe(start_cell, end_cell):\n",
    "    data_rows = []\n",
    "    for row in network_sc_sheet[start_cell: end_cell]:\n",
    "        data_cols = []\n",
    "        for cell in row:\n",
    "            data_cols.append(cell.value)\n",
    "        data_rows.append(data_cols)\n",
    "    coverted_df = pd.DataFrame(data_rows) \n",
    "    return coverted_df\n",
    "\n",
    "get_dataframe('AZ20', 'BF29')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to extract numeric value from character string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_numeric(number_str):\n",
    "    list_of_chars = list(str(number_str))\n",
    "    \n",
    "    first_num_index = -1\n",
    "    \n",
    "    was_int = 0\n",
    "    \n",
    "    last_num_index = len(list_of_chars)-1\n",
    "    for x in range(0, len(list_of_chars)):\n",
    "        try:\n",
    "            char_as_num = int(list_of_chars[x])\n",
    "            was_int = 1\n",
    "        except ValueError:\n",
    "            was_int = 0\n",
    "        if was_int == 1:\n",
    "            break\n",
    "            \n",
    "    first_num_index = x\n",
    "    # print first_num_index\n",
    "    \n",
    "    was_char = 1\n",
    "    \n",
    "    for x in range(last_num_index, -1, -1):\n",
    "        try:\n",
    "            char_as_num = int(list_of_chars[x])\n",
    "            was_char = 0\n",
    "        except ValueError:\n",
    "            last_num_index -= 1\n",
    "            was_char = 1\n",
    "        if was_char == 0:\n",
    "            break\n",
    "    last_num_index = x\n",
    "    # print last_num_index\n",
    "    \n",
    "    return float(\"\".join(list_of_chars[first_num_index: last_num_index+1]))\n",
    "    \n",
    "convert_to_numeric('82.33')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base cell ref changed at this step -- Move to separate function\n",
    "\n",
    "#### Dates validated\n",
    "\n",
    "Check for Network Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility function to check missing and zero values in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "\n",
    "def check_missing_and_zero_values(column_list):\n",
    "    for value in column_list:\n",
    "            if isinstance(value, numbers.Number) is False:\n",
    "                if value is None:\n",
    "                    print (\"Missing values in First Table\")\n",
    "                    return False\n",
    "                else:\n",
    "                    try:\n",
    "                        length = len(value)\n",
    "                        if length < 2:\n",
    "                            print (\"Missing values in First Table\")\n",
    "                            return False\n",
    "                    except:\n",
    "                        print (\"Unknown stuff in First Table\")\n",
    "                        return False\n",
    "            else:\n",
    "                # number\n",
    "                number_as_float = float(value)\n",
    "                if float(value) == 0.0:\n",
    "                    print (\"Zero values in First Table\")\n",
    "                    return False\n",
    "                \n",
    "    return True\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to check 1st table data\n",
    "\n",
    "> Make it resuable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_smart_pricing_data(first_table_df):\n",
    "    \n",
    "    # maybe date check should be done here\n",
    "    \n",
    "    # first_table_df[3][1] = 0\n",
    "    # first_table_df[2][3] = '*'\n",
    "    # first_table_df[2][4] = None\n",
    "    \n",
    "    # check for missing data\n",
    "\n",
    "    # print first_table_df.columns\n",
    "\n",
    "    for column_index in first_table_df.columns[1:]:\n",
    "        column_values = first_table_df[column_index][1:].tolist()\n",
    "        if check_missing_and_zero_values(column_values) is False:\n",
    "            print (\"Smart Pricing Data Missing\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    print (\"Smart Pricing data ok\")\n",
    "    return True\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_first_table_data(first_table_df):\n",
    "    \n",
    "    # maybe date check should be done here\n",
    "    \n",
    "    # first_table_df[3][1] = 0\n",
    "    # first_table_df[2][3] = '*'\n",
    "    # first_table_df[2][4] = None\n",
    "    \n",
    "    if first_table_df.shape == (10, 7):\n",
    "        \n",
    "        # check for missing data\n",
    "        \n",
    "        first_table_df.drop([4], axis = 1, inplace = True)\n",
    "        # print first_table_df.columns\n",
    "        \n",
    "        for column_index in first_table_df.columns[1:]:\n",
    "            column_values = first_table_df[column_index][1:].tolist()\n",
    "            if check_missing_and_zero_values(column_values) is False:\n",
    "                return False\n",
    "    \n",
    "\n",
    "        \n",
    "        print (\"First Table data ok\")\n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print (\"Dimension of First Table does not match\")\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def organic_metrics_validation(first_table_df):\n",
    "    \n",
    "    if first_table_df.shape == (10, 6):\n",
    "        \n",
    "        required_column = first_table_df[1][1:].tolist()\n",
    "        print (required_column)\n",
    "        \n",
    "        organic_metrics = required_column[:6]\n",
    "        non_organic_metrics = required_column[6:]\n",
    "        \n",
    "        oRev = organic_metrics[5]\n",
    "        oVol = organic_metrics[4]\n",
    "        Rev = non_organic_metrics[0]\n",
    "        Vol = non_organic_metrics[1]\n",
    "        \n",
    "        print (oRev, oVol, Rev, Vol)\n",
    "        \n",
    "        # test case: oRev = 10.00\n",
    "        \n",
    "        oRev = convert_to_numeric(oRev)\n",
    "        oVol = convert_to_numeric(oVol)\n",
    "        Rev = convert_to_numeric(Rev)\n",
    "        Vol = convert_to_numeric(Vol)\n",
    "        \n",
    "        print (oRev, oVol, Rev, Vol)\n",
    "        \n",
    "        if Rev < oRev or Vol < oVol:\n",
    "            print (\"Organic metrics greater than combined metrics which is not possible\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print (\"Dimension of First Table does not match\")\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Network Summary First table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates validated in First Table\n",
      "First Table data ok\n",
      "[81.58, '93.4¢', 0.087, 0.65, '104mm', '$8.51mm', '$8.53mm', '117mm', 72.95]\n",
      "$8.51mm 104mm $8.53mm 117mm\n",
      "8.51 104.0 8.53 117.0\n",
      "All ok in First Table!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_first_table():\n",
    "    cell_ref = get_cell_ref(3)\n",
    "    first_heading = str(read_data(cell_ref))\n",
    "    # print first_heading\n",
    "    \n",
    "    if first_heading.strip() != 'NETWORK SUMMARY':\n",
    "        print (\"Cannot find heading: NETWORK SUMMARY\")\n",
    "        return False\n",
    "    else:\n",
    "        # all ok until now\n",
    "        # try to find second heading\n",
    "        \n",
    "        second_heading = str(read_data(get_cell_ref(5)))\n",
    "        if second_heading.strip() != 'Bing O&O Core Browse':\n",
    "            print (\"Cannot find heading: Bing O&O Core Browse\")\n",
    "            return False\n",
    "        else:\n",
    "            # read in the range of cells\n",
    "            start_cell = get_cell_ref(6)\n",
    "            # print start_cell\n",
    "            \n",
    "            end_cell = traverse_cells(start_cell, widths[0]-1, heights[0]-1, 0)\n",
    "            # print end_cell\n",
    "            \n",
    "            network_summary_first_table_df = get_dataframe(start_cell, end_cell)\n",
    "            \n",
    "            \n",
    "            network_summary_first_table_date = network_summary_first_table_df.loc[0][1]\n",
    "            network_summary_first_table_date = datetime.datetime.date(network_summary_first_table_date)\n",
    "            \n",
    "            # print network_sc_date_as_date\n",
    "            \n",
    "            # print network_summary_first_table_date\n",
    "            \n",
    "            if (network_sc_date_as_date - network_summary_first_table_date).days == 1:\n",
    "                print (\"Dates validated in First Table\")\n",
    "                \n",
    "                # check table data\n",
    "                if check_first_table_data(network_summary_first_table_df) is False:\n",
    "                    return False\n",
    "                \n",
    "                if organic_metrics_validation(network_summary_first_table_df) is False:\n",
    "                    return False\n",
    "            \n",
    "            else:\n",
    "                print (\"Dates not validated in First Table\")\n",
    "                return False\n",
    "            \n",
    "            print (\"All ok in First Table!!\")\n",
    "            \n",
    "            return True\n",
    "    \n",
    "\n",
    "network_summary_first_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Nw Summary Second Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates validated in Second Table\n",
      "First Table data ok\n",
      "All ok in Second Table!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_second_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[1], y_offsets[1]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    if second_heading.strip() != 'Yahoo O&O':\n",
    "        print (\"Cannot find heading: Yahoo O&O\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[1], y_offsets[1], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[1] + widths[1] - 1, y_offsets[1] + heights[1] - 1, 0)\n",
    "\n",
    "        network_summary_second_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_second_table_date = network_summary_second_table_df.loc[0][1]\n",
    "        network_summary_second_table_date = datetime.datetime.date(network_summary_second_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_second_table_date).days == 1:\n",
    "            print (\"Dates validated in Second Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_first_table_data(network_summary_second_table_df) is False:\n",
    "                return False\n",
    "\n",
    "        else:\n",
    "            print (\"Dates not validated in Second Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Second Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_second_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check NW Summary Third Table (Smart Pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZ20 BF29\n",
      "Dates validated in Third Table\n",
      "Missing values in First Table\n",
      "Missing values in First Table\n",
      "Smart Pricing Data Missing\n",
      "Samrt Pricing Data not available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def network_summary_third_table():\n",
    "    \n",
    "    cell_ref = traverse_cells(base_cell, x_offsets[2], y_offsets[2]-1, 0)\n",
    "    second_heading = str(read_data(cell_ref))\n",
    "    \n",
    "    if second_heading.strip() != 'Yahoo Syndication':\n",
    "        print (\"Cannot find heading: Yahoo Syndication\")\n",
    "        return False\n",
    "    else:\n",
    "    \n",
    "        # read in the range of cells\n",
    "        start_cell = traverse_cells(base_cell, x_offsets[2], y_offsets[2], 0)\n",
    "\n",
    "        end_cell = traverse_cells(base_cell, x_offsets[2] + widths[2] - 1, y_offsets[2] + heights[2] - 1, 0)\n",
    "        \n",
    "        print (start_cell, end_cell)\n",
    "\n",
    "        network_summary_third_table_df = get_dataframe(start_cell, end_cell)\n",
    "        network_summary_third_table_date = network_summary_third_table_df.loc[0][1]\n",
    "        network_summary_third_table_date = datetime.datetime.date(network_summary_third_table_date)\n",
    "\n",
    "        # print network_sc_date_as_date\n",
    "\n",
    "        # print network_summary_first_table_date\n",
    "\n",
    "        if (network_sc_date_as_date - network_summary_third_table_date).days == 1:\n",
    "            print (\"Dates validated in Third Table\")\n",
    "\n",
    "            # check table data\n",
    "            if check_first_table_data(network_summary_third_table_df) is False:\n",
    "                if check_smart_pricing_data(network_summary_third_table_df) is False:\n",
    "                    print (\"Samrt Pricing Data not available\")\n",
    "                    return False\n",
    "                else:\n",
    "                    print (\"Missing values in Third Table\")\n",
    "                    return False\n",
    "        else:\n",
    "            print (\"Dates not validated in Third Table\")\n",
    "            return False\n",
    "\n",
    "        print (\"All ok in Third Table!!\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "network_summary_third_table()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
